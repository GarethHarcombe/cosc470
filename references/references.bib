% Encoding: UTF-8
'
@InProceedings{DelgadoGonzalo2016,
  author     = {Delgado-Gonzalo, R. and Lemkaddem, A. and Renevey, Ph. and Calvo, E. Muntané and Lemay, M. and Cox, K. and Ashby, D. and Willardson, J. and Bertschi, M.},
  booktitle  = {2016 38th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
  title      = {Real-time monitoring of swimming performance},
  year       = {2016},
  address    = {Orlando, FL, USA},
  note       = {ISSN: 1558-4615},
  pages      = {4743--4746},
  publisher  = {IEEE},
  abstract   = {This article presents the performance results of a novel algorithm for swimming analysis in real-time within a low-power wrist-worn device. The estimated parameters are: lap count, stroke count, time in lap, total swimming time, pace/speed per lap, total swam distance, and swimming efficiency (SWOLF). In addition, several swimming styles are automatically detected. Results were obtained using a database composed of 13 different swimmers spanning 646 laps and 858.78 min of total swam time. The final precision achieved in lap detection ranges between 99.7\% and 100\%, and the classification of the different swimming styles reached a sensitivity and specificity above 98\%. We demonstrate that a swimmers performance can be fully analyzed with the smart bracelet containing the novel algorithm. The presented algorithm has been licensed to ICON Health \& Fitness Inc. for their line of wearables under the brand iFit.},
  comment    = {https://ieeexplore.ieee.org/document/7591787},
  date       = {2016-08},
  doi        = {10.1109/EMBC.2016.7591787},
  issn       = {1558-4615},
  keywords   = {Classification algorithms, Algorithm design and analysis, Real-time systems, Accelerometers, Estimation, Wrist, Magnetic sensors},
  readstatus = {read},
}

'
@Misc{science4performance2018,
  author       = {Gavin Francis},
  howpublished = {science4performance},
  month        = aug,
  title        = {Strava – {Automatic} {Lap} {Detection}},
  year         = {2018},
  abstract     = {As you upload your data, you accumulate a growing history of rides. It is helpful to find ways of classifying different types of activities. Races and training sessions often include laps that are …},
  date         = {2018-08},
  journaltitle = {Science4Performance},
  language     = {en},
  readstatus   = {read},
  url          = {https://science4performance.com/2018/08/04/strava-automatic-lap-detection/},
  urldate      = {2023-03-02},
}

'
@Article{Marlantes2022,
  author       = {Marlantes, Kyle E. and Maki, Kevin J.},
  journal      = {Ocean Engineering},
  title        = {A neural-corrector method for prediction of the vertical motions of a high-speed craft},
  year         = {2022},
  issn         = {0029-8018},
  pages        = {112300},
  volume       = {262},
  abstract     = {A machine learning method is developed which is capable of making predictions of nonlinear ship motions in a range of wave conditions when trained on response data from only a single seaway. The method is formulated around the equations of motion in the time domain, but the equations are augmented with data-driven terms that act to correct the force-balance in the equations. The data-driven nonlinear forcing terms are modeled using Long Short-Term Memory (LSTM) recurrent neural networks. The resulting hybrid governing equations are solved numerically. Predictions from the method are compared to nonlinear test data of 2-DOF motion of a Generic Prismatic Planing Hull (GPPH) at forward speed in head seas, with time histories given for both regular and irregular waves. The training data requirements to classify a specific seaway are investigated and quantified. Predictions over a range of significant wave heights and peak periods are performed using training data from only a single seaway to show the effectiveness of the method in generalizing across different environmental conditions.},
  comment      = {LSTM to predict the motion of ships in waves. Similar due to the periodic nature of motion

https://www.sciencedirect.com/science/article/pii/S0029801822015967},
  date         = {2022-10},
  doi          = {10.1016/j.oceaneng.2022.112300},
  file         = {:Marlantes2022 - A Neural Corrector Method for Prediction of the Vertical Motions of a High Speed Craft.html:URL},
  journaltitle = {Ocean Engineering},
  keywords     = {Hybrid method, Data-model fusion, LSTM, Neural network, High-speed, Seakeeping},
  language     = {en},
  readstatus   = {read},
  url          = {https://www.sciencedirect.com/science/article/pii/S0029801822015967},
  urldate      = {2023-03-02},
}

'
@Article{Yin2014,
  author       = {Yin, Jian-Chuan and Zou, Zao-Jian and Xu, Feng and Wang, Ni-Ni},
  journal      = {Neurocomputing},
  title        = {Online ship roll motion prediction based on grey sequential extreme learning machine},
  year         = {2014},
  issn         = {0925-2312},
  month        = apr,
  pages        = {168--174},
  volume       = {129},
  abstract     = {For the online prediction of nonlinear systems with characteristics of time-varying dynamics and uncertainty, a sequential grey prediction approach is proposed based on the online sequential extreme learning machine (OS-ELM). The grey processing of time series alleviates the unfavorable effects of uncertainty in measurement data; the extremely fast learning speed and high generalization accuracy of OS-ELM enable online application of the sequential grey prediction approach. Ship's roll motion at sea is a complex nonlinear process with time-varying dynamics. Its dynamics also involves uncertainty caused by wind, random waves and rudder actions. In this paper, the proposed OS-ELM-based grey prediction approach is implemented for online ship roll prediction. The simulation of prediction is based on measurement data obtained from sea trials of the scientific research and training ship Yu Kun. Simulation results of ship roll prediction demonstrate the effectiveness and efficiency of the proposed grey neural prediction approach in dealing with time-varying nonlinear system with uncertainty.},
  comment      = {Online sequential Extreme Learning model to predict the roll angle of a ship. A lot of physics baked into the model - could be a useful approach. But not trying to predict existing time series data.

https://www.sciencedirect.com/science/article/pii/S0925231213009739},
  date         = {2014-04},
  doi          = {10.1016/j.neucom.2013.09.043},
  file         = {:Yin2014 - Online Ship Roll Motion Prediction Based on Grey Sequential Extreme Learning Machine.html:URL},
  journaltitle = {Neurocomputing},
  keywords     = {Extreme learning machine, Grey prediction, Grey relational analysis, Sequential learning, Radial basis function network, Ship roll prediction},
  language     = {en},
  readstatus   = {read},
  url          = {https://www.sciencedirect.com/science/article/pii/S0925231213009739},
  urldate      = {2023-03-02},
}

'
@InProceedings{ElKassabi2020,
  author     = {El-Kassabi, Hadeel T. and Khalil, Khaled and Serhani, M. Adel},
  booktitle  = {Proceedings of the 13th {International} {Conference} on {Intelligent} {Systems}: {Theories} and {Applications}},
  title      = {Deep {Learning} {Approach} for {Forecasting} {Athletes}' {Performance} in {Sports} {Tournaments}},
  year       = {2020},
  address    = {New York, NY, USA},
  month      = nov,
  pages      = {1--6},
  publisher  = {Association for Computing Machinery},
  series     = {{SITA}'20},
  abstract   = {Sports and international tournaments have gained world attention in the past decade. Enhancing sports activities and promoting sports to participate in international events, competitions, and tournaments play a substantial role in the development and advancement of nations around the globe. In this paper, we applied different deep learning models for predicting athletes' performance in tournaments to help them improve their results. We propose a deep learning selection algorithm to evaluate the effectiveness of the athletes' current training by predicting their race results upon completing each additional training, which potentially improves their performance. We gathered public training data for athletes who participated in the 2017 Boston Marathon within a five-month window prior to the race. Deep learning models were applied and evaluated to predict marathon finishing times. These include Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRU). Results show that Deep Learning models give improved race time prediction accuracy over the baseline machine learning model, such as standard Linear Regression (LR).},
  comment    = {LSTM and Gated Recurrent Memory to predict athletes performance. Key takeaways are picking out relevant features. 

https://dl.acm.org/doi/abs/10.1145/3419604.3419786},
  doi        = {10.1145/3419604.3419786},
  file       = {:ElKassabi2020 - Deep Learning Approach for Forecasting Athletes' Performance in Sports Tournaments.html:URL},
  isbn       = {9781450377331},
  keywords   = {prediction modeling, marathon, Running, sports training, deep learning},
  readstatus = {read},
  url        = {https://doi.org/10.1145/3419604.3419786},
  urldate    = {2023-03-06},
}

'
@Article{Preatoni2020,
  author     = {Preatoni, Ezio and Nodari, Stefano and Lopomo, Nicola Francesco},
  journal    = {Frontiers in Bioengineering and Biotechnology},
  title      = {Supervised {Machine} {Learning} {Applied} to {Wearable} {Sensor} {Data} {Can} {Accurately} {Classify} {Functional} {Fitness} {Exercises} {Within} a {Continuous} {Workout}},
  year       = {2020},
  issn       = {2296-4185},
  month      = jul,
  pages      = {664},
  volume     = {8},
  abstract   = {Observing, classifying and assessing human movements is important in many applied fields, including human-computer interface, clinical assessment, activity monitoring and sports performance. The redundancy of options in planning and implementing motor programmes, the inter- and intra-individual variability in movement execution, and the time-continuous, high-dimensional nature of motion data make segmenting sequential movements into a smaller set of discrete classes of actions non-trivial. We aimed to develop and validate a method for the automatic classification of four popular functional fitness drills, which are commonly performed in current circuit training routines. Five inertial measurement units were located on the upper and lower limb, and on the trunk of fourteen participants. Positions were chosen by keeping into account the dynamics of the movement and the positions where commercially-available smart technologies are typically secured. Accelerations and angular velocities were acquired continuously from the units and used to train and test different supervised learning models, including k-Nearest Neighbors (kNN) and support-vector machine (SVM) algorithms. The use of different kernel functions, as well as different strategies to segment continuous inertial data were explored. Classification performance was assessed from both the training dataset (k-fold cross-validation), and a test dataset (leave-one-subject-out validation). Classification from different subsets of the measurement units was also evaluated (1-sensor and 2-sensor data). SVM with a cubic kernel and fed with data from 600 ms windows with a 10\% overlap gave the best classification performances, yielding to an overall accuracy of 97.8\%. This approach did not misclassify any functional fitness movement for another, but confused relatively frequently (2.8–18.9\%) a fitness movement phase with the transition between subsequent repetitions of the same task or different drills. Among 1-sensor configurations, the upper arm achieved the best classification performance (96.4\% accuracy), whereas combining the upper arm and the thigh sensors obtained the highest level of accuracy (97.6\%) from 2-sensors movement tracking. We found that supervised learning can successfully classify complex sequential movements such as those of functional fitness workouts. Our approach, which could exploit technologies currently available in the consumer market, demonstrated exciting potential for future on-field applications including unstructured training.},
  comment    = {Uses SVM and kNN to do rolling window classifications on the activity, for cross fit style exercises https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7358600/
Much finer grain data though},
  doi        = {10.3389/fbioe.2020.00664},
  file       = {:preatoni_supervised_2020 - Supervised Machine Learning Applied to Wearable Sensor Data Can Accurately Classify Functional Fitness Exercises within a Continuous Workout.html:URL;:Preatoni2020 - Supervised Machine Learning Applied to Wearable Sensor Data Can Accurately Classify Functional Fitness Exercises within a Continuous Workout.pdf:PDF},
  pmcid      = {PMC7358600},
  pmid       = {32733863},
  readstatus = {read},
  url        = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7358600/},
  urldate    = {2023-03-12},
}

'
@Article{Yoon2021,
  author     = {Yoon, Aejung and Kim, Sung Jin},
  journal    = {INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER},
  title      = {A deep-learning approach for predicting oscillating motion of liquid slugs in a closed-loop pulsating heat pipe},
  year       = {2021},
  issn       = {0017-9310},
  volume     = {181},
  abstract   = {This paper presents the very first application of a deep neural network (DNN) model to predict the oscillating motion of liquid slugs in a closed-loop pulsating heat pipe (CLPHP). The time-series data of the positions of liquid-vapor menisci are obtained from flow visualization using a high-speed camera: five liquid slugs in the 5-turn CLPHP are observed to have rapid oscillation with varying amplitude. Time series analysis is conducted on the flow visualization results by employing the DNN model, which uses a Long Short-Term Memory (LSTM)-based encoder-decoder architecture as a sequence-to-sequence deep learning framework. From the model, the position of each meniscus is predicted with a single input data of its own (univariate prediction) or with multiple input data of all the menisci (multivariate prediction): It is shown that the predicted values match closely with the measured values for both univariate and multivariate predictions. To quantitatively examine the prediction performance, the average volumetric fraction in the condenser section, a major parameter for the thermal performance of the CLPHP, is calculated using the predicted values of positions of menisci. This model is found to be accurate to within +/- 30\% in predicting the average volumetric fraction for both univariate and multivariate cases. This study sheds new light on analyzing the dynamics of the complex oscillating motion in pulsating heat pipes. (c) 2021 Elsevier Ltd. All rights reserved.},
  comment    = {Deep learning LSTM to predict periodic behaviour of liquids. Not super relevant, we're not trying to predict time series data, more annotate existing data.

https://koasas.kaist.ac.kr/handle/10203/288452},
  doi        = {10.1016/j.ijheatmasstransfer.2021.121860},
  language   = {English},
  publisher  = {PERGAMON-ELSEVIER SCIENCE LTD},
  readstatus = {read},
  url        = {https://koasas.kaist.ac.kr/handle/10203/288452},
  urldate    = {2023-03-12},
}

'
@Article{Wang2018a,
  author   = {Wang, Ze and Hu, Chuxiong and Zhu, Yu and He, Suqin and Zhang, Ming and Mu, Haihua},
  journal  = {IEEE Transactions on Industrial Electronics},
  title    = {Newton-{ILC} {Contouring} {Error} {Estimation} and {Coordinated} {Motion} {Control} for {Precision} {Multiaxis} {Systems} {With} {Comparative} {Experiments}},
  year     = {2018},
  issn     = {1557-9948},
  month    = feb,
  number   = {2},
  pages    = {1470--1480},
  volume   = {65},
  abstract = {This paper proposes a Newton extremum seeking algorithm based iterative learning coordinated control (Newton-ILC) strategy for contouring motion accuracy of precision multiaxial systems. Specifically, as the contouring error estimation is critically important for coordinated contouring motion control, a cost function is constructed based on the reference contour, as well as the current position, and the minimal value of the function is searched to determine the contouring error point through an offline Newton algorithm. Consequently, high precision estimation of the contouring error can be achieved, even under extreme contouring tasks with high speed, large curvature, and sharp corners. The calculated contouring error is then projected to each axis, and the axial contouring errors are controlled by iterative learning method, while the learning results will be used to adjust the axial position reference commands for contouring accuracy improvement. Comparative experiments are conducted on a biaxial linear motor stage to validate the practical effectiveness of the proposed Newton-ILC strategy. The experimental results illustrate that the proposed Newton-ILC achieves not only nearly perfect contouring error estimation but obvious improvement of contouring accuracy as well after a few iterations. Particularly, in some extreme cases such as large initial tracking error, high speed, large curvature, and sharp corners, the proposed Newton-ILC strategy can achieve rather excellent contouring performance when compared with individual axis control, conditional cross-coupled control, and cross-coupled iterative learning coordinated control (CCILC) methods.},
  comment  = {https://ieeexplore.ieee.org/document/7995126},
  doi      = {10.1109/TIE.2017.2733455},
  keywords = {Adaptive control, Motion control, Error analysis, Tracking, Stability analysis, Cost function, Estimation, Contouring error, contouring motion control, iterative learning coordinated control (ILC), multiaxis system, Newton algorithm},
}

'
@Article{Novatchkov2012,
  author     = {Novatchkov, Hristo and Baca, Arnold},
  journal    = {Procedia Engineering},
  title      = {Machine learning methods for the automatic evaluation of exercises on sensor-equipped weight training machines},
  year       = {2012},
  issn       = {1877-7058},
  month      = jan,
  pages      = {562--567},
  volume     = {34},
  abstract   = {The present paper proposes pattern recognition techniques for the evaluation of exercises performed on weight training machines equipped with a load cell and rotary encoder for the measurement of essential force and weight displacement characteristics during training. The latter parameters can be used for the implementation of intelligent modeling methods like artificial neural networks in order to assess the exercise technique automatically and provide the athlete with appropriate feedback. First results of the developed classifiers indicate good performance values and high classification rates, demonstrating a significant potential of machine learning routines for the autonomous evaluation of performances on weight machines.},
  comment    = {Analysing gym workout data, includes segmentation in pipeline before classification. Discusses preprocessing techniques such as a strong low-pass filter. Peak detection techniques for segmentation, looking at force applied (speed is analogous in this project). This paper uses 100Hz frequency data, a lot higher than the 0.5-0.2Hz data collected from GPS watches. 
Then features extracted for each segment

https://www.sciencedirect.com/science/article/pii/S1877705812017092},
  doi        = {10.1016/j.proeng.2012.04.096},
  file       = {:Novatchkov2012 - Machine Learning Methods for the Automatic Evaluation of Exercises on Sensor Equipped Weight Training Machines.html:URL},
  keywords   = {Weight training, machine learning, feedback, ubiquitious computing, sensor technologies},
  language   = {en},
  readstatus = {read},
  series     = {{ENGINEERING} {OF} {SPORT} {CONFERENCE} 2012},
  url        = {https://www.sciencedirect.com/science/article/pii/S1877705812017092},
  urldate    = {2023-03-12},
}

'
@InProceedings{Attigala2019,
  author     = {Attigala, D. A. and Weeraman, R. and Fernando, W. S. S. W and Mahagedara, M. M. S. U and Gamage, M. P. A. W. and Jayakodi, T.},
  booktitle  = {2019 {International} {Conference} on {Computing}, {Power} and {Communication} {Technologies} ({GUCON})},
  title      = {Intelligent {Trainer} for {Athletes} using {Machine} {Learning}},
  year       = {2019},
  address    = {New Delhi, India},
  month      = sep,
  pages      = {898--903},
  publisher  = {IEEE},
  abstract   = {International professional athletes are looked after and trained by a team of professionals consisting of trainers and medical professionals among other. They make sure that the athlete is physically and mentally prepared to compete in a competition, and often train for years for the perfect results. Sri Lankan athletes however do not have the same luxury of being taken cared by a team of such professionals since they are young due to the lack of adequate resources in the country. `Optio' mobile application aims to provide a solution for this problem by creating a mobile application that the athlete constantly has access to, which will provide him/her with dietary, exercise and health related advice catered and customized to each individual athlete's needs. Consequently, this will provide a method which will let the athlete's trainer monitor their athletes easily as well as let them pick the most suitable athlete for a competition.},
  comment    = {https://ieeexplore.ieee.org/document/8940477},
  keywords   = {Training, Stress, Sports, Schedules, Information technology, Injuries, Ontologies, Amazon Machine Learning, Training Stress Balance, Chronic Training Load, Acute Training LoadMetabolism},
  readstatus = {read},
}

'
@InProceedings{Altmayer2000,
  author     = {Altmayer, C.},
  booktitle  = {Proceedings of the {IEEE} {Intelligent} {Vehicles} {Symposium} 2000},
  title      = {Enhancing the integrity of integrated {GPS}/{INS} systems by cycle slip detection and correction},
  year       = {2000},
  address    = {Dearborn, MI, USA},
  month      = oct,
  pages      = {174--179},
  publisher  = {IEEE},
  abstract   = {Satellite navigation systems are widely used for high accuracy applications. Before the carrier phase observable can be utilized as the most accurate ranging information its inherent integer cycle ambiguity must be resolved. The algorithms for ambiguity resolution and carrier phase positioning rely on the ambiguities being constant. However, high dynamics, shadowing or multipath may cause so-called cycle slips which would deteriorate the accuracy if remained undetected. A new method was developed using an integrated system consisting of an inertial measurement unit and a differential GPS (Global Positioning System) sensor. With this method the integrity of cycle slip free carrier phase information is greatly enhanced which was demonstrated in driving tests.},
  comment    = {Techniques exist to directly correct errors in GPS data. However, these require the raw values measured from satellites, not the processed coordinates. Hence, we will have to do more macro analysis for detecting and correcting outliers. 

https://ieeexplore.ieee.org/abstract/document/898337},
  doi        = {10.1109/IVS.2000.898337},
  file       = {:Altmayer2000 - Enhancing the Integrity of Integrated GPS_INS Systems by Cycle Slip Detection and Correction.html:URL},
  keywords   = {Global Positioning System, Phase measurement, Vehicle dynamics, Satellite navigation systems, Aircraft navigation, Phase detection, Shadow mapping, Sensor systems, Artificial intelligence, Control systems},
  readstatus = {read},
}

'
@Article{Yu2022,
  author     = {Yu, Qingying and Hu, Fan and Chen, Chuanming and Sun, Liping and Zheng, Xiaoyao},
  journal    = {ISPRS International Journal of Geo-Information},
  title      = {Low-{Frequency} {Trajectory} {Map} {Matching} {Method} {Based} on {Vehicle} {Heading} {Segmentation}},
  year       = {2022},
  number     = {7},
  pages      = {355},
  volume     = {11},
  abstract   = {Numerous Global Positioning System connected vehicles are collecting extensive data remotely in cities, enabling data-driven infrastructure planning. To truly benefit from this emerging technology, it is important to combine telematics and map data to make it easier to extract and mine useful information from the data. By performing map matching, data points that cannot be accurately located on the road network can be projected onto the correct road segment. As an important means of remote data processing, it has become an important pre-processing step in the field of data mining. However, due to the various errors of location devices and the complexity of road networks, map matching technology also faces great challenges. In order to improve the efficiency and accuracy of the map matching algorithm, this study proposes an offline method for low-frequency trajectory data map matching based on vehicle trajectory segmentation. First, the trajectory is segmented based on the vehicle’s travel direction. Then, the comprehensive probability of the corresponding road segment is calculated based on the spatial probability and the directional probability of each road segment around the location. Third, the k candidate matching paths under consideration are selected based on the comprehensive probability evaluation. Finally, the shortest path planning and the probability calculation of the different candidate paths are combined to find the optimal matching path. The experimental results on the real trajectory dataset in Shanghai and the road network environment show that the proposed algorithm has better accuracy, efficiency, and robustness than other algorithms.},
  address    = {Basel, Switzerland},
  comment    = {Snapping location to a map route based on current location, direction traveling. Kalman filter and ANN, Markov chains,  

https://www.proquest.com/docview/2693972904?accountid=14499&pq-origsite=summon},
  copyright  = {© 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  doi        = {10.3390/ijgi11070355},
  file       = {:Yu2022 - Low Frequency Trajectory Map Matching Method Based on Vehicle Heading Segmentation.pdf:PDF},
  keywords   = {low-frequency trajectory, map matching, comprehensive probability, shortest-path planning},
  language   = {English},
  publisher  = {MDPI AG},
  readstatus = {read},
  url        = {https://www.proquest.com/docview/2693972904/abstract/270C24F3969A4066PQ/1},
  urldate    = {2023-03-12},
}

'
@Article{Tanaka2021,
  author   = {Tanaka, Akira and Tateiwa, Nariaki and Hata, Nozomi and Yoshida, Akihiro and Wakamatsu, Takashi and Osafune, Shota and Fujisawa, Katsuki},
  journal  = {Transportation Research Part C: Emerging Technologies},
  title    = {Offline map matching using time-expanded graph for low-frequency data},
  year     = {2021},
  issn     = {0968-090X},
  month    = sep,
  pages    = {103265},
  volume   = {130},
  abstract = {Map matching is an essential preprocessing step for most trajectory-based intelligent transport system services. Due to device capability constraints and the lack of a high-performance model, map matching for low-sampling-rate trajectories is of particular interest. Therefore, we developed a time-expanded graph matching (TEG-matching) that has three advantages (1) high speed and accuracy, as it is robust for spatial measurement error and a pause such as at traffic lights; (2) being parameter-free, that is, our algorithm has no predetermined hyperparameters; and (3) only requiring ordered locations for map matching. Given a set of low-frequency GPS data, we construct a time-expanded graph (TEG) whose path from source to sink represents a candidate route. We find the shortest path on TEG to obtain the matching route with a small area between the vehicle trajectory. Additionally, we introduce two general speedup techniques (most map matching methods can apply) bottom-up segmentation and fractional cascading. Numerical experiments with worldwide vehicle trajectories in a public dataset show that TEG-matching outperforms state-of-the-art algorithms in terms of accuracy and speed, and we verify the effectiveness of the two general speedup techniques.},
  comment  = {Segmentation techniques to up-sample data?
https://www.sciencedirect.com/science/article/pii/S0968090X21002771},
  doi      = {10.1016/j.trc.2021.103265},
  file     = {:Tanaka2021 - Offline Map Matching Using Time Expanded Graph for Low Frequency Data.html:URL},
  keywords = {Offline map matching, Time-expanded graph, Neighborhood search analysis, Fractional cascading, Bottom-up segmentation},
  language = {en},
  url      = {https://www.sciencedirect.com/science/article/pii/S0968090X21002771},
  urldate  = {2023-03-12},
}

@Misc{Garmin2023,
  author       = {Garmin},
  title        = {RINEX Logging with the GPSMAP 66, 86 Series and Montana 700 Series},
  howpublished = {Website},
  year         = {2023},
  url          = {https://support.garmin.com/en-NZ/?faq=7iMJZdoCcM2562XlKlMC76},
}

'
@Article{Nweke2018,
  author     = {Nweke, Henry Friday and Teh, Ying Wah and Al-garadi, Mohammed Ali and Alo, Uzoma Rita},
  journal    = {Expert Systems with Applications},
  title      = {Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: {State} of the art and research challenges},
  year       = {2018},
  issn       = {0957-4174},
  month      = sep,
  pages      = {233--261},
  volume     = {105},
  abstract   = {Human activity recognition systems are developed as part of a framework to enable continuous monitoring of human behaviours in the area of ambient assisted living, sports injury detection, elderly care, rehabilitation, and entertainment and surveillance in smart home environments. The extraction of relevant features is the most challenging part of the mobile and wearable sensor-based human activity recognition pipeline. Feature extraction influences the algorithm performance and reduces computation time and complexity. However, current human activity recognition relies on handcrafted features that are incapable of handling complex activities especially with the current influx of multimodal and high dimensional sensor data. With the emergence of deep learning and increased computation powers, deep learning and artificial intelligence methods are being adopted for automatic feature learning in diverse areas like health, image classification, and recently, for feature extraction and classification of simple and complex human activity recognition in mobile and wearable sensors. Furthermore, the fusion of mobile or wearable sensors and deep learning methods for feature learning provide diversity, offers higher generalisation, and tackles challenging issues in human activity recognition. The focus of this review is to provide in-depth summaries of deep learning methods for mobile and wearable sensor-based human activity recognition. The review presents the methods, uniqueness, advantages and their limitations. We not only categorise the studies into generative, discriminative and hybrid methods but also highlight their important advantages. Furthermore, the review presents classification and evaluation procedures and discusses publicly available datasets for mobile sensor human activity recognition. Finally, we outline and explain some challenges to open research problems that require further research and improvements.},
  doi        = {10.1016/j.eswa.2018.03.056},
  file       = {:nweke_deep_2018 - Deep Learning Algorithms for Human Activity Recognition Using Mobile and Wearable Sensor Networks_ State of the Art and Research Challenges.html:URL},
  keywords   = {Deep learning, Mobile and wearable sensors, Human activity recognition, Feature representation, Review},
  language   = {en},
  shorttitle = {Deep learning algorithms for human activity recognition using mobile and wearable sensor networks},
  url        = {https://www.sciencedirect.com/science/article/pii/S0957417418302136},
  urldate    = {2023-04-05},
}

'
@Article{Wang2016,
  author   = {Wang, Zhelong and Wu, Donghui and Chen, Jianming and Ghoneim, Ahmed and Hossain, Mohammad Anwar},
  journal  = {IEEE Sensors Journal},
  title    = {A {Triaxial} {Accelerometer}-{Based} {Human} {Activity} {Recognition} via {EEMD}-{Based} {Features} and {Game}-{Theory}-{Based} {Feature} {Selection}},
  year     = {2016},
  issn     = {1558-1748},
  month    = may,
  number   = {9},
  pages    = {3198--3207},
  volume   = {16},
  abstract = {In recent years, sensor-based human activity recognition has attracted lots of studies. This paper presents a single wearable triaxial accelerometer-based human activity recognition system, which can be used in the real life of activity monitoring. The sensor is attached around different parts of the body: waist and left ankle, respectively. In order to improve the accuracy and reduce the computational complexity, the ensemble empirical mode decomposition (EEMD)-based features and the feature selection (FS) method are introduced, respectively. Considering the feature interaction, a game theory-based FS method is proposed to evaluate the features. Relevant and distinguished features that are robust to the placement of sensors are selected. In the experiment, the data acquired from the two different parts of the body, waist and ankle, are utilized to evaluate the proposed FS method. To verify the effectiveness of the proposed method, k-nearst neighbor and support vector machine are used to recognize the human activities from waist and ankle. Experiment results demonstrate the effectiveness of the introduced EEMD-based features for human activity recognition. Compared with the representative FS methods, including Relief-F and minimum-redundancy maximum-relevance, the proposed FS approach selects fewer features and provides higher accuracy. The results also show that the triaxial accelerometer around the waist produces optimal results.},
  doi      = {10.1109/JSEN.2016.2519679},
  keywords = {Feature extraction, Sensors, Accelerometers, White noise, Biomedical monitoring, Empirical mode decomposition, Game theory, Human Activity Recognition, Game Theory, Feature Selection, Human activity recognition, game theory, feature selection, wearable triaxial accelerometer, EEMD},
}

'
@Article{Zdravevski2017,
  author   = {Zdravevski, Eftim and Lameski, Petre and Trajkovik, Vladimir and Kulakov, Andrea and Chorbev, Ivan and Goleva, Rossitza and Pombo, Nuno and Garcia, Nuno},
  journal  = {IEEE Access},
  title    = {Improving {Activity} {Recognition} {Accuracy} in {Ambient}-{Assisted} {Living} {Systems} by {Automated} {Feature} {Engineering}},
  year     = {2017},
  issn     = {2169-3536},
  pages    = {5262--5280},
  volume   = {5},
  abstract = {Ambient-assisted living (AAL) is promising to become a supplement of the current care models, providing enhanced living experience to people within context-aware homes and smart environments. Activity recognition based on sensory data in AAL systems is an important task because 1) it can be used for estimation of levels of physical activity, 2) it can lead to detecting changes of daily patterns that may indicate an emerging medical condition, or 3) it can be used for detection of accidents and emergencies. To be accepted, AAL systems must be affordable while providing reliable performance. These two factors hugely depend on optimizing the number of utilized sensors and extracting robust features from them. This paper proposes a generic feature engineering method for selecting robust features from a variety of sensors, which can be used for generating reliable classification models. From the originally recorded time series and some newly generated time series [i.e., magnitudes, first derivatives, delta series, and fast Fourier transformation (FFT)-based series], a variety of time and frequency domain features are extracted. Then, using two-phase feature selection, the number of generated features is greatly reduced. Finally, different classification models are trained and evaluated on an independent test set. The proposed method was evaluated on five publicly available data sets, and on all of them, it yielded better accuracy than when using hand-tailored features. The benefits of the proposed systematic feature engineering method are quickly discovering good feature sets for any given task than manually finding ones suitable for a particular task, selecting a small feature set that outperforms manually determined features in both execution time and accuracy, and identification of relevant sensor types and body locations automatically. Ultimately, the proposed method could reduce the cost of AAL systems by facilitating execution of algorithms on devices with limited resources and by using as few sensors as possible.},
  doi      = {10.1109/ACCESS.2017.2684913},
  file     = {:Zdravevski2017 - Improving Activity Recognition Accuracy in Ambient Assisted Living Systems by Automated Feature Engineering.pdf:PDF},
  keywords = {Feature extraction, Windows, Activity recognition, Sensor phenomena and characterization, Robustness, Ambient assisted living, Feature extraction, time series analysis, ambient intelligence, wearable sensors, sensor fusion, pattern recognition, data mining, data preprocessing, body sensor networks},
}

'
@Article{Abidine2018,
  author   = {Abidine, Bilal M’hamed and Fergani, Lamya and Fergani, Belkacem and Oussalah, Mourad},
  journal  = {Pattern Analysis and Applications},
  title    = {The joint use of sequence features combination and modified weighted {SVM} for improving daily activity recognition},
  year     = {2018},
  issn     = {1433-755X},
  month    = feb,
  number   = {1},
  pages    = {119--138},
  volume   = {21},
  abstract = {Two serious problems affecting the implementation of human activity recognition algorithms have been acknowledged.The first one corresponds to non-informative sequence features. The second is the class imbalance in the training data due to the fact that people do not spend the same amount of time on the different activities. To address these issues, we propose a new scheme based on a combination of principal component analysis, linear discriminant analysis (LDA) and the modified weighted support vector machines. First we added the most significant principal components to the set of features extracted using LDA. This work shows that a suitable sequence feature set combined with the modified WSVM based on our criterion classifier achieves good improvement and efficiency over the traditional used methods.},
  doi      = {10.1007/s10044-016-0570-y},
  file     = {:Abidine2018 - The Joint Use of Sequence Features Combination and Modified Weighted SVM for Improving Daily Activity Recognition.html:URL},
  keywords = {Activity recognition, PCA, LDA, SVM, Imbalanced data classification},
  language = {en},
  url      = {https://doi.org/10.1007/s10044-016-0570-y},
  urldate  = {2023-04-06},
}

@InProceedings{Ploetz2011,
  author    = {Thomas Pl{\"o}tz and Hammerla, {Nils Y.} and Patrick Olivier},
  booktitle = {IJCAI 2011 - 22nd International Joint Conference on Artificial Intelligence},
  title     = {Feature learning for activity recognition in ubiquitous computing},
  year      = {2011},
  address   = {University of Michigan, Department of Naval Architecture and Marine Engineering, Ann Arbor, 48109, MI, USA},
  month     = dec,
  note      = {International Joint Conference on Artificial Intelligence 2011, IJCAI 2011 ; Conference date: 16-07-2011 Through 22-07-2011},
  pages     = {1729--1734},
  publisher = {Ocean Engineering},
  volume    = {262},
  abstract  = {Feature extraction for activity recognition in context-aware ubiquitous computing applications is usually a heuristic process, informed by underlying domain knowledge. Relying on such explicit knowledge is problematic when aiming to generalize across different application domains. We investigate the potential of recent machine learning methods for discovering universal features for context-aware applications of activity recognition. We also describe an alternative data representation based on the empirical cumulative distribution function of the raw data, which effectively abstracts from absolute values. Experiments on accelerometer data from four publicly available activity recognition datasets demonstrate the significant potential of our approach to address both contemporary activity recognition tasks and next generation problems such as skill assessment and the detection of novel activities.},
  day       = {1},
  doi       = {10.5591/978-1-57735-516-8/IJCAI11-290},
  isbn      = {9781577355120},
  language  = {English},
  url       = {https://www.ijcai.org/proceedings/2011},
}


@Article{Prochazka2014,
  author   = {Procházka,Ales and Vaseghi,Saeed and Yadollahi,Mohammadreza and Upa,Ondrej and Mares,Jan and Vysata,Oldrich},
  journal  = {Medical and Biological Engineering and Computing},
  title    = {Remote physiological and GPS data processing in evaluation of physical activities},
  year     = {2014},
  month    = {04},
  note     = {Copyright - International Federation for Medical and Biological Engineering 2014; Last updated - 2022-11-13},
  number   = {4},
  pages    = {301-8},
  volume   = {52},
  abstract = {The monitoring of data from global positioning system (GPS) receivers and remote sensors of physiological and environmental data allow forming an information database for observed data processing. In this paper, we propose the use of such a database for the analysis of physical activities during cycling. The main idea of the proposed algorithm is to use cross-correlations between the heart rate and the altitude gradient to evaluate the delay between these variables and to study its time evolution. The data acquired during 22 identical cycling routes, each about 130 km long, include more than 6,700 segments of length 60 s recorded with varying sampling periods. General statistical and digital signal processing methods used include mathematical tools to reject gross errors, resampling using selected interpolation methods, digital filtering of noise signal components, and estimating cross-correlations between the position data and the physiological signals. The results of a regression between GPS and physiological data include the estimate of the time delay between the heart rate change and gradient altitude of about 7.5 s and its decrease during each training route.PUBLICATION ABSTRACT]},
  isbn     = {01400118},
  keywords = {Medical Sciences--Computer Applications; Global positioning systems--GPS; Data processing; Data acquisition systems; Computer science; Analysis; Studies; Physiology; Accuracy; Sensors; Signal processing; Altitude; Correlation analysis; Heart rate; Bicycling; 51821:Data Processing, Hosting, and Related Services; 2600:Management science/operations research; 9130:Experimental/theoretical; 5240:Software & systems; 51741:Satellite Telecommunications; Geography; Regression Analysis; Algorithms; Heart Rate -- physiology; Bicycling -- physiology; Humans; Geographic Information Systems; Telemetry -- methods; Signal Processing, Computer-Assisted},
  language = {English},
  url      = {https://www.proquest.com/scholarly-journals/remote-physiological-gps-data-processing/docview/1508631402/se-2},
}

'
@Article{Charvatova2017,
  author   = {Charvátová, Hana and Procházka, Aleš and Vaseghi, Saeed and Vyšata, Oldřich and Vališ, Martin},
  journal  = {Signal, Image and Video Processing},
  title    = {{GPS}-based analysis of physical activities using positioning and heart rate cycling data},
  year     = {2017},
  issn     = {1863-1711},
  month    = feb,
  number   = {2},
  pages    = {251--258},
  volume   = {11},
  abstract = {This paper addresses the use of multichannel signal processing methods in analysis of heart rate changes during cycling using the global positioning system (GPS) to record the route conditions. The main objectives of this work are in monitoring of physiological activities, cycling features extraction, their classification and visualization. Real data were acquired from 41 cycling rides of the same 11.48-km long route divided into 2460 segments of approximately 60 s. The data were recorded with a varying sampling period within the range of 1–22 s depending on the route profile. The pre-processing stage included preparatory analysis, filtering and resampling of the data to a constant sampling rate. The proposed algorithm includes the evaluation of the cross-correlation between the heart rate and the altitude gradient as recorded by a GPS satellite system. A Bayesian approach was then applied to classify the cycling segment features into two classes (specifying cycling up and down) with the classification accuracy better than 93 \%. A comparison with other classification methods is presented in the paper as well. The results include the following relationships: (1) the heart rate and altitude gradient, which shared a positive correlation coefficient of 0.62; (2) the heart rate and speed, which shared a negative correlation coefficient of −0.72 over all of the analysed segments; and (3) the mean heart rate change delay (6.8–11.5 s) in relation to the changes in the altitude gradients associated with cycling up and down. The paper forms a contribution to the use of computational intelligence and visualization for data processing both in cycling and fitness physical activities as well.},
  doi      = {10.1007/s11760-016-0928-z},
  file     = {:Charvatova2017 - GPS Based Analysis of Physical Activities Using Positioning and Heart Rate Cycling Data.html:URL},
  keywords = {Cycling data processing, GPS data acquisition, Data fusion, Biomedical signal analysis, Feature extraction, Bayesian classification},
  language = {en},
  url      = {https://doi.org/10.1007/s11760-016-0928-z},
  urldate  = {2023-04-14},
}

'
@TechReport{Snyder1987,
  author       = {John P. Snyder},
  institution  = {U.S Geological Survey},
  title        = {Map projections: {A} working manual},
  year         = {1987},
  address      = {Washington, D.C.},
  type         = {{USGS} {Numbered} {Series}},
  abstract     = {After decades of using only one map projection, the Polyconic, for its mapping program, the U.S. Geological Survey (USGS) now uses several of the more common projections for its published maps. For larger scale maps, including topographic quadrangles and the State Base Map Series, conformal projections such as the Transverse Mercator and the Lambert Conformal Conic are used. Equal-area and equidistant projections appear in the National Atlas. Other projections, such as the Miller Cylindrical and the Van der Grinten, are chosen occasionally for convenience, sometimes making use of existing base maps prepared by others. Some projections treat the Earth only as a sphere, others as either ellipsoid or sphere. The USGS has also conceived and designed several new projections, including the Space Oblique Mercator, the first map projection designed to permit mapping of the Earth continuously from a satellite with low distortion. The mapping of extraterrestrial bodies has resulted in the use of standard projections in completely new settings. Several other projections which have not been used by the USGS are frequently of interest to the cartographic public. With increased computerization, it is important to realize that rectangular coordinates for all these projections may be mathematically calculated with formulas which would have seemed too complicated in the past, but which now may be programmed routinely, especially if aided by numerical examples. A discussion of appearance, usage, and history is given together with both forward and inverse equations for each projection involved.},
  collaborator = {Snyder, John P.},
  doi          = {10.3133/pp1395},
  journal      = {Map projections: A working manual},
  school       = {U.S. Government Printing Office},
  series       = {Professional {Paper}},
  shorttitle   = {Map projections},
  url          = {http://pubs.er.usgs.gov/publication/pp1395},
  urldate      = {2023-05-26},
}

'
@Article{Wu2018,
  author   = {Wu, Shaoen and Xu, Junhong and Zhu, Shangyue and Guo, Hanqing},
  journal  = {Signal Processing},
  title    = {A {Deep} {Residual} convolutional neural network for facial keypoint detection with missing labels},
  year     = {2018},
  issn     = {0165-1684},
  month    = mar,
  pages    = {384--391},
  volume   = {144},
  abstract = {Keypoint detection is critical in image recognitions. Deep learning such as convolutional neural network (CNN) has recently demonstrated its tremendous success in detecting image keypoints over conventional image processing methodologies. The deep learning solutions, however, heavily rely on labeling target images for their reliability and accuracy. Unfortunately, most image datasets do not have all labels marked. To address this problem, this paper presents an effective and novel deep learning solution, Masked Loss Residual Convolutional Neural Network (ML-ResNet), to facial keypoint detection on the datasets that have missing target labels. The core of ML-ResNet is a masked loss objective function that ignores the error in predicting the missing target keypoints in the output layer of a CNN. To compensate for the loss induced by the masked loss objective function that likely results in overfitting, ML-ResNet is designed of a data augmentation strategy to increase the number of training data. The performance of ML-ResNet has been evaluated on the image dataset from Kaggle Facial Keypoints Detection competition, which consists of 7049 training images, but with only 2140 images that have full target keypoints labeled. In the experiments, ML-ResNet is compared to a pioneer literature CNN facial keypoint detection work. The experiment results clearly show that the proposed ML-ResNet is robust and advantageous in training CNNs on datasets with missing target values. ML-ResNet can improve the learning time by 30\% during the training and the detection accuracy by eight times in facial keypoint detection.},
  doi      = {10.1016/j.sigpro.2017.11.003},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0165168417303924/pdfft?md5=9dca069542f86ff3914107b74ecfe858&pid=1-s2.0-S0165168417303924-main.pdf&isDTMRedir=Y:application/pdf},
  keywords = {Deep learning, Facial keypoint detection},
  language = {en},
  url      = {https://www.sciencedirect.com/science/article/pii/S0165168417303924},
  urldate  = {2023-04-25},
}

@Article{Dumas2022,
  author        = {Dumas, Joe},
  journal       = {International Journal of Computer Science and Information Technology, Volume 14, Number 1, February 2022},
  title         = {Accuracy of Garmin GPS Running Watches over Repetitive Trials on the Same Route},
  year          = {2022},
  month         = mar,
  abstract      = {Many runners use watches incorporating Global Positioning System technology to track their workouts. These devices can be valuable training aids, but they have limitations. For several reasons including variations in satellite position, environmental factors, and design decisions made by the manufacturer, GPS-enabled watches can produce position measurement errors. These can result in incorrect estimations of total distance covered as well as running pace. This study examined the accuracy of three Garmin running watches of different technological generations using repetitive trials, over several years, by the same runner over the same route. The older watches, a Forerunner 205 and a Forerunner 220, showed similar accuracy when traversing the route. The newer generation watch, a Forerunner 45S, was found to be significantly less accurate in terms of both the trueness and precision of its distance measurements. This may indicate that Garmin, in competition with other manufacturers of similar devices, has chosen in recent years to prioritize device miniaturization and battery life over accuracy.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  doi           = {10.48550/ARXIV.2203.00491},
  eprint        = {2203.00491},
  file          = {:http\://arxiv.org/pdf/2203.00491v1:PDF},
  keywords      = {Other Computer Science (cs.OH), FOS: Computer and information sciences},
  primaryclass  = {cs.OH},
  publisher     = {arXiv},
}
'

@TechReport{He2015,
  author        = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title         = {Deep {Residual} {Learning} for {Image} {Recognition}},
  institution   = {Microsoft Research},
  year          = {2015},
  month         = dec,
  note          = {arXiv:1512.03385 [cs] type: article},
  __markedentry = {[gareth:6]},
  abstract      = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  annote        = {Comment: Tech report},
  doi           = {10.48550/arXiv.1512.03385},
  file          = {:He2015 - Deep Residual Learning for Image Recognition.pdf:PDF},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  school        = {arXiv},
  url           = {http://arxiv.org/abs/1512.03385},
  urldate       = {2023-04-19},
}

@Misc{Garmin2023a,
  author        = {Garmin},
  title         = {What Can Cause GPS Accuracy Issues on My Fitness Device?},
  howpublished  = {Website},
  month         = apr,
  year          = {2023},
  note          = {Accessed April 15, 2023},
  __markedentry = {[gareth:6]},
  owner         = {Garmin},
  url           = {https://support.garmin.com/en-US/?faq=z0n0KE1XVF0Pe4Su8QiZgA},
}

@Misc{DepartmentofLocalGovernment2023,
  author        = {Department of Local Government, Sport and Cultural Industries},
  title         = {Athletics track events},
  howpublished  = {Website},
  month         = apr,
  year          = {2023},
  note          = {Accessed on April 21, 2023},
  __markedentry = {[gareth:6]},
  url           = {https://www.dlgsc.wa.gov.au/sport-and-recreation/sports-dimensions-guide/athletics-track-events},
}

@Misc{Triastcyn2019,
  author        = {Aleksei Triastcyn and Boi Faltings},
  title         = {Generating Artificial Data for Private Deep Learning},
  year          = {2019},
  __markedentry = {[gareth:6]},
  archiveprefix = {arXiv},
  eprint        = {1803.03148},
  primaryclass  = {cs.LG},
}

@Misc{Goodfellow2014,
  author        = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  title         = {Generative Adversarial Networks},
  year          = {2014},
  __markedentry = {[gareth:6]},
  archiveprefix = {arXiv},
  eprint        = {1406.2661},
  primaryclass  = {stat.ML},
}

'

@Article{Saxena2021,
  author        = {Saxena, Divya and Cao, Jiannong},
  title         = {Generative {Adversarial} {Networks} ({GANs}): {Challenges}, {Solutions}, and {Future} {Directions}},
  journal       = {ACM Computing Surveys},
  year          = {2021},
  volume        = {54},
  number        = {3},
  pages         = {63:1--63:42},
  month         = may,
  issn          = {0360-0300},
  __markedentry = {[gareth:6]},
  abstract      = {Generative Adversarial Networks (GANs) is a novel class of deep generative models that has recently gained significant attention. GANs learn complex and high-dimensional distributions implicitly over images, audio, and data. However, there exist major challenges in training of GANs, i.e., mode collapse, non-convergence, and instability, due to inappropriate design of network architectre, use of objective function, and selection of optimization algorithm. Recently, to address these challenges, several solutions for better design and optimization of GANs have been investigated based on techniques of re-engineered network architectures, new objective functions, and alternative optimization algorithms. To the best of our knowledge, there is no existing survey that has particularly focused on the broad and systematic developments of these solutions. In this study, we perform a comprehensive survey of the advancements in GANs design and optimization solutions proposed to handle GANs challenges. We first identify key research issues within each design and optimization technique and then propose a new taxonomy to structure solutions by key research issues. In accordance with the taxonomy, we provide a detailed discussion on different GANs variants proposed within each solution and their relationships. Finally, based on the insights gained, we present promising research directions in this rapidly growing field.},
  doi           = {10.1145/3446374},
  keywords      = {GANs variants, computer vision, Image generation, mode collapse, GANs, deep Generative models, GANs applications, Deep learning, GANs Survey, GANs challenges, Generative Adversarial Networks},
  shorttitle    = {Generative {Adversarial} {Networks} ({GANs})},
  url           = {https://doi.org/10.1145/3446374},
  urldate       = {2023-04-19},
}

@InProceedings{Altwaijry2016,
  author        = {Altwaijry, Hani and Veit, Andreas and Belongie, Serge J and Tech, Cornell},
  title         = {Learning to detect and match keypoints with deep architectures.},
  booktitle     = {BMVC},
  year          = {2016},
  __markedentry = {[gareth:6]},
  url           = {https://www.researchgate.net/profile/Andreas-Veit/publication/317191594\_Learning\_to\_Detect\_and\_Match\_Keypoints
  \_with\_Deep\_Architectures/links /5a2f59a30f7e9bfe817035f7/Learning-to-Detect-and-Match-Keypoints-with-Deep-Architectures.pdf},
}

'

@Article{Lowe2004,
  author        = {Lowe, David G.},
  title         = {Distinctive {Image} {Features} from {Scale}-{Invariant} {Keypoints}},
  journal       = {International Journal of Computer Vision},
  year          = {2004},
  volume        = {60},
  number        = {2},
  pages         = {91--110},
  month         = nov,
  issn          = {1573-1405},
  __markedentry = {[gareth:6]},
  abstract      = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  doi           = {10.1023/B:VISI.0000029664.99615.94},
  file          = {:Lowe2004 - Distinctive Image Features from Scale Invariant Keypoints.html:URL},
  keywords      = {invariant features, object recognition, scale invariance, image matching},
  language      = {en},
  url           = {https://doi.org/10.1023/B:VISI.0000029664.99615.94},
  urldate       = {2023-04-27},
}

'

@Article{Zhang2021,
  author        = {Zhang, Jing and Chen, Zhe and Tao, Dacheng},
  title         = {Towards {High} {Performance} {Human} {Keypoint} {Detection}},
  journal       = {International Journal of Computer Vision},
  year          = {2021},
  volume        = {129},
  number        = {9},
  pages         = {2639--2662},
  month         = sep,
  issn          = {1573-1405},
  __markedentry = {[gareth:6]},
  abstract      = {Human keypoint detection from a single image is very challenging due to occlusion, blur, illumination, and scale variance. In this paper, we address this problem from three aspects by devising an efficient network structure, proposing three effective training strategies, and exploiting four useful postprocessing techniques. First, we find that context information plays an important role in reasoning human body configuration and invisible keypoints. Inspired by this, we propose a cascaded context mixer (CCM), which efficiently integrates spatial and channel context information and progressively refines them. Then, to maximize CCM’s representation capability, we develop a hard-negative person detection mining strategy and a joint-training strategy by exploiting abundant unlabeled data. It enables CCM to learn discriminative features from massive diverse poses. Third, we present several sub-pixel refinement techniques for postprocessing keypoint predictions to improve detection accuracy. Extensive experiments on the MS COCO keypoint detection benchmark demonstrate the superiority of the proposed method over representative state-of-the-art (SOTA) methods. Our single model achieves comparable performance with the winner of the 2018 COCO Keypoint Detection Challenge. The final ensemble model sets a new SOTA on this benchmark. The source code will be released at https://github.com/chaimi2013/CCM.},
  doi           = {10.1007/s11263-021-01482-8},
  file          = {:Zhang2021 - Towards High Performance Human Keypoint Detection.html:URL},
  keywords      = {Human Pose Estimation, Deep Nerual Networks, Sub-pixel Refinement, Context},
  language      = {en},
  url           = {https://doi.org/10.1007/s11263-021-01482-8},
  urldate       = {2023-04-27},
}

'

@Misc{PyTorch2023,
  author        = {PyTorch},
  title         = {{PyTorch} Docs},
  month         = apr,
  year          = {2023},
  note          = {Accessed April 29, 2023},
  __markedentry = {[gareth:6]},
  abstract      = {An open source machine learning framework that accelerates the path from research prototyping to production deployment.},
  language      = {en},
  url           = {https://www.pytorch.org},
  urldate       = {2023-04-29},
}

'

@Article{He2018,
  author        = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
  title         = {Mask {R}-{CNN}},
  journal       = {arXiv},
  year          = {2018},
  month         = jan,
  note          = {arXiv:1703.06870 [cs] type: article},
  __markedentry = {[gareth:6]},
  abstract      = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
  annote        = {Comment: open source; appendix on more results},
  doi           = {10.48550/arXiv.1703.06870},
  file          = {:He2018 - Mask R CNN.pdf:PDF},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  school        = {arXiv},
  url           = {http://arxiv.org/abs/1703.06870},
  urldate       = {2023-04-29},
}

@Misc{PyTorch2023a,
  author        = {PyTorch},
  title         = {Keypoint R-CNN ResNet-50-FPN},
  howpublished  = {Website},
  month         = apr,
  year          = {2023},
  note          = {Accessed on April 29, 2023},
  __markedentry = {[gareth:6]},
  url           = {https://pytorch.org/vision/0.12/generated/torchvision.models.detection. keypointrcnn\_resnet50\_fpn.html},
}

'

@InProceedings{Deng2009,
  author        = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  title         = {{ImageNet}: {A} large-scale hierarchical image database},
  booktitle     = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
  year          = {2009},
  pages         = {248--255},
  month         = jun,
  note          = {ISSN: 1063-6919},
  __markedentry = {[gareth:6]},
  abstract      = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  doi           = {10.1109/CVPR.2009.5206848},
  issn          = {1063-6919},
  keywords      = {Large-scale systems, Image databases, Explosions, Internet, Robustness, Information retrieval, Image retrieval, Multimedia databases, Ontologies, Spine},
  shorttitle    = {{ImageNet}},
}

@Misc{OpenCV2023,
  author        = {OpenCV},
  title         = {Morphological Transformations},
  howpublished  = {Website},
  month         = apr,
  year          = {2023},
  note          = {Accessed on April 29, 2023},
  __markedentry = {[gareth:6]},
  url           = {https://docs.opencv.org/4.x/d9/d61/tutorial\_py\_morphological\_ops.html},
}

'

@Misc{Derpanis2010,
  author        = {Konstantinos G. Derpanis},
  title         = {Overview of the RANSAC Algorithm},
  month         = may,
  year          = {2010},
  __markedentry = {[gareth:6]},
  accessdate    = {2023-04-30},
  file          = {:http\://rmozone.com/snapshots/2015/07/cdg-room-refs/ransac.pdf:PDF},
  url           = {http://rmozone.com/snapshots/2015/07/cdg-room-refs/ransac.pdf},
}

'

@Article{Canny1986,
  author        = {Canny, John},
  title         = {A {Computational} {Approach} to {Edge} {Detection}},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year          = {1986},
  volume        = {PAMI-8},
  number        = {6},
  pages         = {679--698},
  month         = nov,
  issn          = {1939-3539},
  __markedentry = {[gareth:6]},
  abstract      = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
  doi           = {10.1109/TPAMI.1986.4767851},
  file          = {:Canny1986 - A Computational Approach to Edge Detection.html:URL},
  keywords      = {Image edge detection, Detectors, Machine vision, Shape measurement, Performance analysis, Uncertainty, Gaussian approximation, Signal to noise ratio, Signal synthesis, Feature extraction, Edge detection, feature extraction, image processing, machine vision, multiscale image analysis},
}

'

@Article{Chiang2014,
  author        = {Chiang, Yao-Yi and Leyk, Stefan and Knoblock, Craig A.},
  title         = {A {Survey} of {Digital} {Map} {Processing} {Techniques}},
  journal       = {ACM Computing Surveys},
  year          = {2014},
  volume        = {47},
  number        = {1},
  pages         = {1:1--1:44},
  month         = may,
  issn          = {0360-0300},
  __markedentry = {[gareth:6]},
  abstract      = {Maps depict natural and human-induced changes on earth at a fine resolution for large areas and over long periods of time. In addition, maps—especially historical maps—are often the only information source about the earth as surveyed using geodetic techniques. In order to preserve these unique documents, increasing numbers of digital map archives have been established, driven by advances in software and hardware technologies. Since the early 1980s, researchers from a variety of disciplines, including computer science and geography, have been working on computational methods for the extraction and recognition of geographic features from archived images of maps (digital map processing). The typical result from map processing is geographic information that can be used in spatial and spatiotemporal analyses in a Geographic Information System environment, which benefits numerous research fields in the spatial, social, environmental, and health sciences. However, map processing literature is spread across a broad range of disciplines in which maps are included as a special type of image. This article presents an overview of existing map processing techniques, with the goal of bringing together the past and current research efforts in this interdisciplinary field, to characterize the advances that have been made, and to identify future research directions and opportunities.},
  doi           = {10.1145/2557423},
  file          = {:Chiang2014 - A Survey of Digital Map Processing Techniques.html:URL},
  keywords      = {pattern recognition, color segmentation, image processing, graphics recognition, Map processing, geographic information systems},
  url           = {https://dl.acm.org/doi/10.1145/2557423},
  urldate       = {2023-05-02},
}

'

@Article{Rosenfeld1977,
  author        = {A. Rosenfeld and G. J. VanderBrug},
  title         = {Coarse-{Fine} {Template} {Matching}},
  journal       = {IEEE Transactions on Systems, Man, and Cybernetics},
  year          = {1977},
  volume        = {7},
  number        = {2},
  pages         = {104--107},
  month         = feb,
  issn          = {2168-2909},
  __markedentry = {[gareth:6]},
  doi           = {10.1109/TSMC.1977.4309663},
  file          = {:1977 - Coarse Fine Template Matching.pdf:PDF},
  keywords      = {Computational efficiency, Pattern recognition, Spatial resolution, Costs, Clustering algorithms, Data analysis, Pattern classification, Writing, Reconnaissance, Taxonomy},
}

'

@Article{Yang2019,
  author        = {Yang, Hua and Huang, Chenghui and Wang, Feiyue and Song, Kaiyou and Zheng, Shijiao and Yin, Zhouping},
  title         = {Large-scale and rotation-invariant template matching using adaptive radial ring code histograms},
  journal       = {Pattern Recognition},
  year          = {2019},
  volume        = {91},
  pages         = {345--356},
  month         = jul,
  issn          = {0031-3203},
  __markedentry = {[gareth:6]},
  abstract      = {Although template matching has been widely studied in the fields of image processing and computer vision, current template matching methods still cannot address large-scale changes and rotation changes simultaneously. In this study, we propose a novel adaptive radial ring code histograms (ARRCH) image descriptor for large-scale and rotation-invariant template matching. The image descriptor is constructed by (1) identifying, inside the template, a set of concentric ring regions around a reference point, (2) detecting “stable” pixels based on the ASGO, which is tolerant with respect to large scale change, (3) extracting a rotation-invariant feature for each “stable” pixel, and (4) discretizing the features in a separate histogram for each concentric ring region in the scale space. Finally, an ARRCH image descriptor is obtained by chaining the histograms of all concentric ring regions for each scale. In matching mode, a sliding window approach is used to extract descriptors, which are compared with the template one, and a coarse-to-fine search strategy is employed to detect the scale of the target image. To demonstrate the performance of the ARRCH, several experiments are carried out, including a parameter experiment and a large-scale and rotation change matching experiment, and some applications are presented. The experimental results demonstrate that the proposed method is more resistant to large-scale and rotation differences than previous state-of-the-art matching methods.},
  doi           = {10.1016/j.patcog.2019.03.003},
  file          = {:Yang2019 - Large Scale and Rotation Invariant Template Matching Using Adaptive Radial Ring Code Histograms.html:URL},
  keywords      = {Template matching, Adaptive radial ring code histograms, Large-scale and rotation-invariant features},
  language      = {en},
  url           = {https://www.sciencedirect.com/science/article/pii/S0031320319301025},
  urldate       = {2023-05-02},
}

@Misc{Saxton2023,
  author       = {Athletics Nelson},
  title        = {Run, Jump, Throw | Athletics at Saxton Field},
  howpublished = {Website},
  year         = {2023},
  url          = {https://www.saxtonfield.co.nz/sport/athletics/},
}

@Misc{WorldAthletics2023,
  author       = {World Athletics},
  title        = {IAAF Track and Field Facilities Manual},
  howpublished = {Website},
  year         = {2008},
  url          = {https://worldathletics.org/about-iaaf/documents/technical-information},
}

@TechReport{Priya2022,
  author      = {Bala Priya},
  title       = {Regularization in Neural Networks},
  institution = {Pinecone},
  year        = {2022},
  type        = {techreport},
  url         = {https://www.pinecone.io/learn/regularization-in-neural-networks/#L1-and-L2-Regularization},
}

@Article{s21248309,
  author         = {Lee, Inwoong and Kim, Doyoung and Wee, Dongyoon and Lee, Sanghoon},
  title          = {An Efficient Human Instance-Guided Framework for Video Action Recognition},
  journal        = {Sensors},
  year           = {2021},
  volume         = {21},
  number         = {24},
  issn           = {1424-8220},
  abstract       = {In recent years, human action recognition has been studied by many computer vision researchers. Recent studies have attempted to use two-stream networks using appearance and motion features, but most of these approaches focused on clip-level video action recognition. In contrast to traditional methods which generally used entire images, we propose a new human instance-level video action recognition framework. In this framework, we represent the instance-level features using human boxes and keypoints, and our action region features are used as the inputs of the temporal action head network, which makes our framework more discriminative. We also propose novel temporal action head networks consisting of various modules, which reflect various temporal dynamics well. In the experiment, the proposed models achieve comparable performance with the state-of-the-art approaches on two challenging datasets. Furthermore, we evaluate the proposed features and networks to verify the effectiveness of them. Finally, we analyze the confusion matrix and visualize the recognized actions at human instance level when there are several people.},
  article-number = {8309},
  doi            = {10.3390/s21248309},
  pubmedid       = {34960404},
  url            = {https://www.mdpi.com/1424-8220/21/24/8309},
}

@Misc{Virgolin2021,
  author      = {Marco Virgolin},
  title       = {Time complexity for different machine learning algorithms},
  month       = feb,
  year        = {2021},
  institution = {GitHub},
  url         = {https://marcovirgolin.github.io/extras/details_time_complexity_machine_learning_algorithms/},
}

@Comment{jabref-meta: databaseType:bibtex;}
