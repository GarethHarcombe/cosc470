
    

<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="applicable-device" content="pc,mobile">
    <meta name="access" content="No">

    
    
    <meta name="twitter:site" content="@SpringerLink"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Distinctive Image Features from Scale-Invariant Keypoints"/>
    <meta name="twitter:description" content="International Journal of Computer Vision - This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different..."/>
    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/11263/60/2.jpg"/>
    <meta name="journal_id" content="11263"/>
    <meta name="dc.title" content="Distinctive Image Features from Scale-Invariant Keypoints"/>
    <meta name="dc.source" content="International Journal of Computer Vision 2004 60:2"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Springer"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2004 Kluwer Academic Publishers"/>
    <meta name="dc.rights" content="2004 Kluwer Academic Publishers"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."/>
    <meta name="prism.issn" content="1573-1405"/>
    <meta name="prism.publicationName" content="International Journal of Computer Vision"/>
    <meta name="prism.volume" content="60"/>
    <meta name="prism.number" content="2"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="91"/>
    <meta name="prism.endingPage" content="110"/>
    <meta name="prism.copyright" content="2004 Kluwer Academic Publishers"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://link.springer.com/article/10.1023/B:VISI.0000029664.99615.94"/>
    <meta name="prism.doi" content="doi:10.1023/B:VISI.0000029664.99615.94"/>
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1023/B:VISI.0000029664.99615.94.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1023/B:VISI.0000029664.99615.94"/>
    <meta name="citation_journal_title" content="International Journal of Computer Vision"/>
    <meta name="citation_journal_abbrev" content="International Journal of Computer Vision"/>
    <meta name="citation_publisher" content="Kluwer Academic Publishers"/>
    <meta name="citation_issn" content="1573-1405"/>
    <meta name="citation_title" content="Distinctive Image Features from Scale-Invariant Keypoints"/>
    <meta name="citation_volume" content="60"/>
    <meta name="citation_issue" content="2"/>
    <meta name="citation_publication_date" content="2004/11"/>
    <meta name="citation_firstpage" content="91"/>
    <meta name="citation_lastpage" content="110"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1023/B:VISI.0000029664.99615.94"/>
    <meta name="DOI" content="10.1023/B:VISI.0000029664.99615.94"/>
    <meta name="size" content="117394"/>
    <meta name="citation_doi" content="10.1023/B:VISI.0000029664.99615.94"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1023/B:VISI.0000029664.99615.94&amp;api_key="/>
    <meta name="description" content="This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different view"/>
    <meta name="dc.creator" content="Lowe, David G."/>
    <meta name="dc.subject" content="Computer Imaging, Vision, Pattern Recognition and Graphics"/>
    <meta name="dc.subject" content="Artificial Intelligence"/>
    <meta name="dc.subject" content="Image Processing and Computer Vision"/>
    <meta name="dc.subject" content="Pattern Recognition"/>
    <meta name="citation_reference" content="Arya, S. and Mount, D.M. 1993. Approximate nearest neighbor queries in fixed dimensions. In Fourth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA&#39;93),pp. 271&#8211;280."/>
    <meta name="citation_reference" content="citation_journal_title=Journal of the ACM; citation_title=Anoptimal algorithm for approximate nearest neighbor searching; citation_author=S. Arya, D.M. Mount, N.S. Netanyahu, R. Silverman, A.Y. Wu; citation_volume=45; citation_publication_date=1998; citation_pages=891-923; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Pattern Recognition; citation_title=Generalizing the Hough transform to detect arbitrary patterns; citation_author=D.H. Ballard; citation_volume=13; citation_issue=2; citation_publication_date=1981; citation_pages=111-122; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Computer Vision; citation_title=Recognition using region correspondences; citation_author=R. Basri, D.W. Jacobs; citation_volume=25; citation_issue=2; citation_publication_date=1997; citation_pages=145-166; citation_id=CR4"/>
    <meta name="citation_reference" content="Baumberg, A. 2000. Reliable feature matching across widely separated views. In Conference on ComputerVision andPattern Recognition, Hilton Head, South Carolina, pp. 774&#8211;781."/>
    <meta name="citation_reference" content="Beis, J. and Lowe, D.G. 1997. Shape indexing using approximate nearest-neighbour search in high-dimensional spaces. In Conference on Computer Vision and Pattern Recognition, Puerto Rico, pp. 1000&#8211;1006."/>
    <meta name="citation_reference" content="Brown, M. and Lowe, D.G. 2002. Invariant features from interest point groups. In British Machine Vision Conference, Cardiff, Wales, pp. 656&#8211;665."/>
    <meta name="citation_reference" content="Carneiro, G. and Jepson, A.D. 2002. Phase-based local features. In European Conference on Computer Vision (ECCV), Copenhagen, Denmark, pp. 282&#8211;296."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. on Pattern Analysis and Machine Intelligence; citation_title=Arepresentation for shape based on peaks and ridges in the difference of low-pass transform; citation_author=J.L. Crowley, A.C. Parker; citation_volume=6; citation_issue=2; citation_publication_date=1984; citation_pages=156-170; citation_id=CR9"/>
    <meta name="citation_reference" content="Edelman, S., Intrator, N., and Poggio, T. 1997. Complex cells and object recognition. Unpublished manuscript: http://kybele.psych.cornell.edu/~edelman/archive.html"/>
    <meta name="citation_reference" content="Fergus, R., Perona, P., and Zisserman, A. 2003. Object class recognition by unsupervised scale-invariant learning. In IEEE Conference on Computer Vision and Pattern Recognition, Madison, Wisconsin, pp. 264&#8211;271."/>
    <meta name="citation_reference" content="citation_journal_title=ACMTransactions on Mathematical Software; citation_title=An algorithm for finding best matches in logarithmic expected time; citation_author=J.H. Friedman, J.L. Bentley, R.A. Finkel; citation_volume=3; citation_issue=3; citation_publication_date=1977; citation_pages=209-226; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. on Pattern Analysis and Machine Intelligence; citation_title=Color constant color indexing; citation_author=B.V. Funt, G.D. Finlayson; citation_volume=17; citation_issue=5; citation_publication_date=1995; citation_pages=522-529; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_title=Object Recognition by Computer: The Role of Geometric Constraints; citation_publication_date=1990; citation_id=CR14; citation_author=E. Grimson; citation_publisher=The MIT Press"/>
    <meta name="citation_reference" content="Harris, C. 1992. Geometry from visual motion. In Active Vision, A. Blake and A. Yuille (Eds.), MIT Press, pp. 263&#8211;284."/>
    <meta name="citation_reference" content="Harris, C. and Stephens, M. 1988. Acombined corner and edge detector. In Fourth Alvey Vision Conference, Manchester, UK, pp. 147&#8211;151."/>
    <meta name="citation_reference" content="citation_title=Multiple view geometry in computer vision; citation_publication_date=2000; citation_id=CR17; citation_author=R. Hartley; citation_author=A. Zisserman; citation_publisher=Cambridge University Press"/>
    <meta name="citation_reference" content="Hough, P.V.C. 1962. Method and means for recognizing complex patterns. U.S. Patent 3069654."/>
    <meta name="citation_reference" content="citation_journal_title=Biological Cybernetics; citation_title=The structure of images; citation_author=J.J. Koenderink; citation_volume=50; citation_publication_date=1984; citation_pages=363-396; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Computer Vision; citation_title=Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention; citation_author=T. Lindeberg; citation_volume=11; citation_issue=3; citation_publication_date=1993; citation_pages=283-318; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Statistics; citation_title=Scale-space theory: A basic tool for analysing structures at different scales; citation_author=T. Lindeberg; citation_volume=21; citation_issue=2; citation_publication_date=1994; citation_pages=224-270; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. on Pattern Analysis and Machine Intelligence; citation_title=Fitting parameterized three-dimensional models to images; citation_author=D.G. Lowe; citation_volume=13; citation_issue=5; citation_publication_date=1991; citation_pages=441-450; citation_id=CR22"/>
    <meta name="citation_reference" content="Lowe, D.G. 1999. Object recognition from local scale-invariant features. In International Conference on Computer Vision, Corfu, Greece, pp. 1150&#8211;1157."/>
    <meta name="citation_reference" content="Lowe, D.G. 2001. Local feature view clustering for 3D object recognition. IEEE Conference on Computer Vision and Pattern Recognition, Kauai, Hawaii, pp. 682&#8211;688."/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Computer Vision; citation_title=The fundamental matrix: Theory, algorithms, and stability analysis; citation_author=Q.T. Luong, O.D. Faugeras; citation_volume=17; citation_issue=1; citation_publication_date=1996; citation_pages=43-76; citation_id=CR25"/>
    <meta name="citation_reference" content="Matas, J., Chum, O., Urban, M., and Pajdla, T. 2002. Robust wide baseline stereo from maximally stable extremal regions. In British Machine Vision Conference, Cardiff, Wales, pp. 384&#8211;393."/>
    <meta name="citation_reference" content="Mikolajczyk, K. 2002. Detection of local features invariant to affine transformations, Ph.D. thesis, Institut National Polytechnique de Grenoble, France."/>
    <meta name="citation_reference" content="Mikolajczyk, K. and Schmid, C. 2002. An affine invariant interest point detector. In European Conference on Computer Vision (ECCV), Copenhagen, Denmark, pp. 128&#8211;142."/>
    <meta name="citation_reference" content="Mikolajczyk, K., Zisserman, A., and Schmid, C. 2003. Shape recognition with edge-based features. In Proceedings of the British Machine Vision Conference, Norwich, U.K."/>
    <meta name="citation_reference" content="Moravec, H. 1981. Rover visual obstacle avoidance. In International Joint Conference on Artificial Intelligence, Vancouver, Canada, pp. 785&#8211;790."/>
    <meta name="citation_reference" content="citation_journal_title=Vision Research; citation_title=Large-scale tests of a keyed, appearance-based 3-D object recognition system; citation_author=R.C. Nelson, A. Selinger; citation_volume=38; citation_issue=15; citation_publication_date=1998; citation_pages=2469-2488; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Computer Vision; citation_title=Probabilistic models of appearance for 3-D object recognition; citation_author=A.R. Pope, D.G. Lowe; citation_volume=40; citation_issue=2; citation_publication_date=2000; citation_pages=149-167; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Computer Graphics Forum (Eurographics 2003); citation_title=Cloth motion capture; citation_author=D. Pritchard, W. Heidrich; citation_volume=22; citation_issue=3; citation_publication_date=2003; citation_pages=263-271; citation_id=CR33"/>
    <meta name="citation_reference" content="Schaffalitzky, F. and Zisserman, A. 2002. Multi-view matching for unordered image sets, or &#39;How do I organize my holiday snaps?&#39;&#8221; In European Conference on Computer Vision, Copenhagen, Denmark, pp. 414&#8211;431."/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Computer Vision; citation_title=Recognition without correspondence using multidimensional receptive field histograms; citation_author=B. Schiele, J.L. Crowley; citation_volume=36; citation_issue=1; citation_publication_date=2000; citation_pages=31-50; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. on Pattern Analysis and Machine Intelligence; citation_title=Local grayvalue invariants for image retrieval; citation_author=C. Schmid, R. Mohr; citation_volume=19; citation_issue=5; citation_publication_date=1997; citation_pages=530-534; citation_id=CR36"/>
    <meta name="citation_reference" content="Se, S., Lowe, D.G., and Little, J. 2001. Vision-based mobile robot localization and mapping using scale-invariant features. In International Conference on Robotics and Automation, Seoul, Korea, pp. 2051&#8211;2058."/>
    <meta name="citation_reference" content="Se, S., Lowe, D.G., and Little, J. 2002. Global localization using distinctive visual features. In International Conference on Intelligent Robots and Systems, IROS 2002, Lausanne, Switzerland, pp. 226&#8211;231."/>
    <meta name="citation_reference" content="citation_journal_title=Image and Vision Computing; citation_title=View-based object recognition using saliency maps; citation_author=A. Shokoufandeh, I. Marsic, S.J. Dickinson; citation_volume=17; citation_publication_date=1999; citation_pages=445-460; citation_id=CR39"/>
    <meta name="citation_reference" content="Torr, P. 1995. Motion segmentation and outlier detection, Ph.D. Thesis, Dept. of Engineering Science, University of Oxford, UK."/>
    <meta name="citation_reference" content="Tuytelaars, T. and Van Gool, L. 2000. Wide baseline stereo based on local, affinely invariant regions. In British Machine Vision Conference, Bristol, UK, pp. 412&#8211;422."/>
    <meta name="citation_reference" content="Weber, M., Welling, M., and Perona, P. 2000. Unsupervised learning of models for recognition. In European Conference on Computer Vision, Dublin, Ireland, pp. 18&#8211;32."/>
    <meta name="citation_reference" content="Witkin, A.P. 1983. Scale-space filtering. In International Joint Conference on Artificial Intelligence, Karlsruhe, Germany, pp. 1019&#8211;1022."/>
    <meta name="citation_reference" content="citation_journal_title=Artificial Intelligence; citation_title=Arobust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry; citation_author=Z. Zhang, R. Deriche, O. Faugeras, Q.T. Luong; citation_volume=78; citation_publication_date=1995; citation_pages=87-119; citation_id=CR44"/>
    <meta name="citation_author" content="Lowe, David G."/>
    <meta name="citation_author_email" content="Lowe@cs.ubc.ca"/>
    <meta name="citation_author_institution" content="Computer Science Department, University of British Columbia, Vancouver, Canada"/>
    <meta name="format-detection" content="telephone=no"/>
    <meta name="citation_cover_date" content="2004/11/01"/>
    

    
    
    <meta property="og:url" content="https://link.springer.com/article/10.1023/B:VISI.0000029664.99615.94"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="SpringerLink"/>
    <meta property="og:title" content="Distinctive Image Features from Scale-Invariant Keypoints - International Journal of Computer Vision"/>
    <meta property="og:description" content="This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."/>
    <meta property="og:image" content="https://media.springernature.com/w200/springer-static/cover/journal/11263.jpg"/>
    


    <title>Distinctive Image Features from Scale-Invariant Keypoints | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    
    
        <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { html{text-size-adjust:100%;-webkit-font-smoothing:subpixel-antialiased;box-sizing:border-box;color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:100%;height:100%;line-height:1.61803;overflow-y:scroll}body,img{max-width:100%}body{background:#fcfcfc;font-size:1.125rem;line-height:1.5;min-height:100%}main{display:block}h1{font-family:Georgia,Palatino,serif;font-size:2.25rem;font-style:normal;font-weight:400;line-height:1.4}a{background-color:transparent;color:#004b83;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border:0;height:auto;vertical-align:middle}button,input{font-family:inherit;font-size:100%}input{line-height:1.15}button,input{overflow:visible}button{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;line-height:inherit}*{margin:0}h2{font-size:1.75rem}h2,h3{font-family:Georgia,Palatino,serif;font-weight:400;line-height:1.4}h3{font-size:1.5rem}h2,h3{font-style:normal}label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}*{box-sizing:inherit}body,button,div,form,input,p{margin:0;padding:0}h1,h2,h3{margin:0}h2+*{margin-block-start:1rem}h1+*{margin-block-start:3rem}[style*="display: none"]:first-child+*{margin-block-start:0}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}.c-ad--728x90 iframe{height:90px;max-width:970px}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}.js .u-show-following-ad+.c-ad--728x90{display:block}}.c-ad iframe{border:0;overflow:auto;vertical-align:top}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-breadcrumbs>li{display:inline}.c-card{background-color:transparent;border:0;box-shadow:none;flex-direction:column;font-size:14px;min-width:0;padding:0}.c-card,.c-card__image{display:flex;overflow:hidden;position:relative}.c-card__image{justify-content:center;padding-bottom:56.25%}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-skip-link{background:#f7fbfe;bottom:auto;color:#004b83;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#004b83}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #ccc;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-pagination{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;list-style:none;margin:0;padding:16px}@media only screen and (min-width:540px){.c-pagination{justify-content:center}}.c-pagination__item{margin-bottom:8px;margin-right:16px}.c-pagination__item:last-child{margin-right:0}.c-pagination__link{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;min-width:30px;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link svg,.c-pagination__link--disabled svg{fill:currentcolor}.c-pagination__link:visited{color:#004b83}.c-pagination__link:focus,.c-pagination__link:hover{border:1px solid #666;text-decoration:none}.c-pagination__link:focus,.c-pagination__link:hover{background-color:#666;background-image:none;color:#fff}.c-pagination__link:focus svg path,.c-pagination__link:hover svg path{fill:#fff}.c-pagination__link--disabled{align-items:center;background-color:transparent;background-image:none;border-radius:2px;color:#333;cursor:default;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;opacity:.67;padding:8px;position:relative;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link--disabled:visited{color:#333}.c-pagination__link--disabled,.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{border:1px solid #ccc;text-decoration:none}.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{background-color:transparent;background-image:none;color:#333}.c-pagination__link--disabled:focus svg path,.c-pagination__link--disabled:hover svg path{fill:#333}.c-pagination__link--active{background-color:#666;background-image:none;border-color:#666;color:#fff;cursor:default}.c-pagination__ellipsis{background:0 0;border:0;min-width:auto;padding-left:0;padding-right:0}.c-pagination__icon{fill:#999;height:12px;width:16px}.c-pagination__icon--active{fill:#004b83}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#666;height:10px;margin:4px 4px 0;width:10px}.c-header{background-color:#fff;border-bottom:4px solid #00285a;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;padding:16px 0}.c-header__container,.c-header__menu{align-items:center;display:flex;flex-wrap:wrap}@supports (gap:2em){.c-header__container,.c-header__menu{gap:2em 2em}}.c-header__menu{list-style:none;margin:0;padding:0}.c-header__item{color:inherit}@supports not (gap:2em){.c-header__item{margin-left:24px}}.c-header__container{justify-content:space-between;margin:0 auto;max-width:1280px;padding:0 16px}@supports not (gap:2em){.c-header__brand{margin-right:32px}}.c-header__brand a{display:block;text-decoration:none}.c-header__link{color:inherit}.c-popup-search{background-color:#eee;box-shadow:0 3px 3px -3px rgba(0,0,0,.21);padding:16px 0;position:relative;z-index:10}@media only screen and (min-width:1024px){.js .c-popup-search{position:absolute;top:100%;width:100%}.c-popup-search__container{margin:auto;max-width:70%}}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Georgia,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;margin-top:0;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #f2f2f2;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-breadcrumbs--truncated .c-breadcrumbs__link{display:inline-block;max-width:45%;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom;white-space:nowrap}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-style:normal;font-weight:700;line-height:1.4;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-reading-companion__panel--active{display:block}.c-article-section__figure-description{font-size:1rem}.c-article-section__figure-description>*{margin-bottom:0}.c-cod{display:block;font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff}.c-pdf-download__link .u-icon{padding-top:2px}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px!important}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-article-extras .c-pdf-container{flex-wrap:wrap;width:100%}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-status-message--success{border-bottom:2px solid #00b8b0;margin-bottom:16px;padding-bottom:16px}.c-recommendations-header{border-bottom:1px solid #d5d5d5}.c-recommendations-title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.24;margin:0;padding-bottom:16px}.c-recommendations-close{background-color:transparent;border:0;cursor:pointer;height:2em;margin-right:-10px;margin-top:-5px;width:2em}.c-recommendations-authors{line-height:1.24;margin-bottom:0}.c-recommendations-list-container{margin-top:0;position:relative}.c-recommendations-list{display:flex;flex-wrap:nowrap;justify-content:space-between;margin:0 auto;overflow-x:hidden;padding:16px 0;scroll-behavior:smooth;scroll-snap-type:x mandatory;width:calc(100% - 146px)}@media only screen and (max-width:539px){.c-recommendations-list{display:block;height:40vh;overflow-y:auto;width:100%}}.c-recommendations-list__item{display:flex;flex:0 0 calc(33.3333% - 16px);margin:0 8px;scroll-snap-align:center}@media only screen and (max-width:539px){.c-recommendations-list__item{margin:0;padding:0 0 16px}}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 16px 0 0;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #d5d5d5;height:auto;min-height:0;position:relative;transform:translateY(0)}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-style:normal;font-weight:700;line-height:1.4rem;margin-bottom:0;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:#004b83;font-size:1.125rem;text-decoration:none}@media only screen and (max-width:539px){.c-recommendations-column-switch{display:flex;flex-direction:column-reverse}}.js-greyout-page-background{background-color:rgba(34,34,34,.75);bottom:0;left:0;position:fixed;right:0;top:0}.app-search__content{display:flex}.app-search__label{color:#666;display:inline-block;font-size:.875rem;margin-bottom:8px}.app-search__input{border:1px solid #b3b3b3;border-bottom-left-radius:3px;border-top-left-radius:3px;box-shadow:inset 0 1px 3px 0 rgba(0,0,0,.21);flex:0 1 auto;font-size:.875rem;line-height:1.2;padding:.75em 1em;vertical-align:middle;width:100%}.app-search__button{align-items:center;background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);border-radius:0 2px 2px 0;color:#fff;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:50px}.app-search__button svg,.u-button svg,.u-button--primary svg{fill:currentcolor}.app-checklist-banner{border:2px solid #ebf1f5;display:flex;flex:1 1 auto;font-size:1rem;justify-content:space-between;margin-bottom:16px;padding:16px}.app-checklist-banner--on-mobile{display:block;margin-bottom:32px}@media only screen and (min-width:1024px){.app-checklist-banner--on-mobile{display:none}}.app-checklist-banner__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;font-weight:700;margin-bottom:0}.app-checklist-banner__icon-container{align-items:center;display:flex;flex:0 0 60px;justify-content:flex-end;width:60px}.app-checklist-banner__link{align-items:center;color:#004b83;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.app-checklist-banner__arrow-icon,.app-checklist-banner__paper-icon{fill:currentcolor;display:inline-block;transform:translate(0);vertical-align:text-top}.app-checklist-banner__paper-icon{height:36px!important;width:36px!important}.app-checklist-banner__arrow-icon{height:11px;margin:4px 0 0 8px;width:16px}.u-button{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);color:#fff}.u-button--full-width{display:flex;width:100%}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-display-block{display:block}.u-display-flex{display:flex;width:100%}.u-flex-direction-column{flex-direction:column}.u-align-items-center{align-items:center}.u-justify-content-space-between{justify-content:space-between}.u-flex-static{flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide{display:none;visibility:hidden}@media print{.u-hide-print{display:none}}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-button-reset{background-color:transparent;border:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-mbs-0{margin-block-start:0!important}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-position-relative{position:relative}.u-mt-0{margin-top:0}.u-mt-32{margin-top:32px}.u-mr-24{margin-right:24px}.u-mb-0{margin-bottom:0}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-ml-8{margin-left:8px}.u-float-left{float:left}.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.u-hide-at-sm{display:none;visibility:hidden}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.u-text-sm{font-size:1rem}.u-h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-style:normal;font-weight:700;line-height:1.4}.hide{display:none;visibility:hidden}.visually-hidden{clip:rect(1px,1px,1px,1px);height:1px;position:absolute!important;width:1px}.c-article-section__figure-description{font-family:Georgia,Palatino,serif}.c-article-section__content p{line-height:1.8}.c-pagination__input{border:1px solid #bfbfbf;border-radius:2px;box-shadow:inset 0 2px 6px 0 rgba(51,51,51,.2);box-sizing:initial;display:inline-block;height:28px;margin:0;max-width:64px;min-width:16px;padding:0 8px;text-align:center;transition:width .15s ease 0s}.c-pagination__input::-webkit-inner-spin-button,.c-pagination__input::-webkit-outer-spin-button{-webkit-appearance:none;margin:0}@media only screen and (min-width:1024px){.c-article-collection__container{display:none}}.c-article-associated-content__container .c-article-associated-content__collection-label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.063rem}.c-article-associated-content__container .c-article-associated-content__collection-title{font-size:1.063rem;font-weight:400}.c-reading-companion__sections-list{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-section__title,.c-article-title{font-weight:400}.c-header__cart-icon{margin-right:12px}.c-header__navigation{display:flex} }</style>



        <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/enhanced-article-6805b3feeb.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
        
    



    
    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1023/B:VISI.0000029664.99615.94","Page":"article","springerJournal":true,"page":{"attributes":{"environment":"live"}},"Country":"NZ","japan":false,"doi":"10.1023-B:VISI.0000029664.99615.94","Journal Title":"International Journal of Computer Vision","Journal Id":11263,"Keywords":"invariant features, object recognition, scale invariance, image matching","kwrd":["invariant_features","object_recognition","scale_invariance","image_matching"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"N","Features":[],"Open Access":"N","hasAccess":"N","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"no-access","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1023-B-VISI.0000029664.99615.94","Full HTML":"N","Subject Codes":["SCI","SCI22005","SCI21000","SCI22021","SCI2203X"],"pmc":["I","I22005","I21000","I22021","I2203X"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-1405","pissn":"0920-5691"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Imaging, Vision, Pattern Recognition and Graphics","2":"Artificial Intelligence","3":"Image Processing and Computer Vision","4":"Pattern Recognition"},"secondarySubjectCodes":{"1":"I22005","2":"I21000","3":"I22021","4":"I2203X"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article"}];
    </script>

    <script>
    window.dataLayer.push({
        ga4MeasurementId: 'G-B3E4QL2TPR',
        ga360TrackingId: 'UA-26408784-1',
        twitterId: 'o47a7',
        ga4ServerUrl: 'https://collect.springer.com',
        imprint: 'springerlink'
    });
</script>

    <script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://collect.springer.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('springer.com') > -1) {
                e.src = 'https://cmp-static.springer.com/production_live/consent-bundle-17-28.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/lib/cookie-consent.min.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>

    <script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
        }
    })(window, document.documentElement);
</script>


    
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



    <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-51eb718839.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-68e3ca1cbd.js', 'async': false},
            ];

            var bodyScripts = [
                
                    {'src': '/oscar-static/js/app-es5-bundle-55e31c31db.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/app-es6-bundle-c4bf80b786.js', 'async': false, 'module': true}
                
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-4799bd8c8d.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-199faa8a7e.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>

    
    
    <link rel="canonical" href="https://link.springer.com/article/10.1023/b:visi.0000029664.99615.94"/>
    

    
    <script type="application/ld+json">{"mainEntity":{"headline":"Distinctive Image Features from Scale-Invariant Keypoints","description":"This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.","datePublished":"","dateModified":"","pageStart":"91","pageEnd":"110","sameAs":"https://doi.org/10.1023/B:VISI.0000029664.99615.94","keywords":"Computer Imaging,Vision,Pattern Recognition and Graphics,Artificial Intelligence,Image Processing and Computer Vision,Pattern Recognition","image":"","isPartOf":{"name":"International Journal of Computer Vision","issn":["1573-1405","0920-5691"],"volumeNumber":"60","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Kluwer Academic Publishers","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Lowe, David G.","affiliation":[{"name":"University of British Columbia","address":{"name":"Computer Science Department, University of British Columbia, Vancouver, Canada","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>

</head>
<body class="shared-article-renderer">
    
    
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://collect.springer.com/ns.html?id=GTM-MRVXSHQ"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


    <div class="u-vh-full">
        <a class="c-skip-link" href="#main-content">Skip to main content</a>
        
            <div class="u-hide u-show-following-ad"></div>
            <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
                <div class="c-ad__inner">
                    <p class="c-ad__label">Advertisement</p>
                    <div id="div-gpt-ad-LB1" data-pa11y-ignore data-gpt data-test="LB1-ad"
                         data-gpt-unitpath="/270604982/springerlink/11263/article" data-gpt-sizes="728x90"
                         style="min-width:728px;min-height:90px" data-gpt-targeting="pos=LB1;articleid=Art1;"></div>
                </div>
            </aside>


<div class="u-position-relative u-mbs-0">
        <header class="c-header u-mb-24" data-test="publisher-header">
    
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-6c9a864b59.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                <span>Search</span>
                <svg class="u-icon u-flex-static u-ml-8" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>

        <div class="c-header__cart-icon">
            <div id="ecommerce-header-cart-icon-link" class="c-header__item ecommerce-cart" style="display:inline-block;margin-right:10px">
 <form action="https://order.springer.com/public/precheckout" method="post">
  <button class="c-header__link" type="submit" style="appearance:none;border:none;background:none;color:inherit;position:relative">
   <svg aria-hidden="true" focusable="false" height="18" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg" style="vertical-align:text-bottom">
    <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z" fill="#333"></path>
   </svg><span class="u-screenreader-only visually-hidden">Go to cart</span><span class="cart-info" style="display:none;position:absolute;top:-4px;right:-10px;background-color:#C40606;color:#fff;width:18px;height:18px;font-size:11px;border-radius:50%;line-height:17.5px;text-align:center"></span></button>
 </form>
 <script>(function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    console.log("listen to updatedCart event");
    document.body.addEventListener("updatedCart", function () {
        console.log("updatedCart happened");
        updateCartIcon().then(function () { return console.log("Cart state update upon event"); });
    }, false);
    return updateCartIcon().then(function () { return console.log("Initial cart state update"); });
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function () { return console.log("Could not fetch cart info"); });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart.springer.com/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()</script>
</div>
        </div>

        <nav class="u-position-relative">
            <ul class="c-header__menu">
                
        
            <li class="c-header__item">
                <a
                    data-test="login-link"
                    class="c-header__link"
                    href="https://link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1023%2FB%3AVISI.0000029664.99615.94"
                    data-track="click"
                    data-track-category="header"
                    data-track-action="login header"
                    data-track-label="link">Log in</a>
            </li>
        

        


            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        
            <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
                <div class="c-popup-search__content">
                    <div class="u-container">
                        <div class="c-popup-search__container" data-test="springerlink-popup-search">
                            <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                        </div>
                    </div>
                </div>
            </div>
        
    
</div>
        
                
    
        <nav class="u-container" aria-label="breadcrumbs" data-test="article-breadcrumbs">
            <ol class="c-breadcrumbs c-breadcrumbs--truncated" itemscope itemtype="https://schema.org/BreadcrumbList">
                
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb1"><span itemprop="name">Home</span></a><meta itemprop="position" content="1">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/journal/11263" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb2"><span itemprop="name">International Journal of Computer Vision</span></a><meta itemprop="position" content="2">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <span itemprop="name">Article</span><meta itemprop="position" content="3">
                    </li>
                
            </ol>
        </nav>
    

        
        
    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            

            
                <div class="c-pdf-button__container u-hide-at-lg js-context-bar-sticky-point-mobile">
                    
                </div>
            

            <div class="c-article-collection__container">
                
    

            </div>


            <article lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2004-11">November 2004</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="">Distinctive Image Features from Scale-Invariant Keypoints</h1>
                        <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-David_G_-Lowe" data-author-popup="auth-David_G_-Lowe">David G. Lowe</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup></li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/11263" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">International Journal of Computer Vision</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>60</b>,<span class="u-visually-hidden">pages </span>91110 (<span data-test="article-publication-year">2004</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">75k <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">37050 <span class="c-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">76 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                    </li>
                
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/article/10.1023/B:VISI.0000029664.99615.94/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>
</div>

                        </div>
                        
    

    

                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.</p></div></div></section>
                    
    


                    
                        
                            <div class="c-notes">
                                <p class="c-notes__text">This is a preview of subscription content, <a id="test-login-banner-link" href="//wayf.springernature.com?redirect_uri&#x3D;https%3A%2F%2Flink.springer.com%2Farticle%2F10.1023%2FB%3AVISI.0000029664.99615.94" data-track="click" data-track-action="login" data-track-label="link">access via your institution</a>.</p>
                            </div>
                        
                        
                            
                            
                                <div data-test="buy-box-mobile" class="c-article-buy-box c-article-buy-box--article">
                                    <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <!-- rendered: 2023-04-27T02:54:23.285344 -->
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box buying-option" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">39,95 </p>
    <p class="buybox__price-info">Price includes VAT (New Zealand)<br></p>
    <form action="https://order.springer.com/public/cart" method="post">
     <input type="hidden" name="type" value="article"><input type="hidden" name="doi" value="10.1023/B:VISI.0000029664.99615.94"><input type="hidden" name="isxn" value="1573-1405"><input type="hidden" name="contenttitle" value="Distinctive Image Features from Scale-Invariant Keypoints"><input type="hidden" name="copyrightyear" value="2004"><input type="hidden" name="year" value=""><input type="hidden" name="authors" value="David G. Lowe"><input type="hidden" name="title" value="International Journal of Computer Vision"><input type="hidden" name="mac" value="37FA1C595DD2E584CE3B33C93541054C"><input type="submit" class="c-box__button" onclick="dataLayer.push({&quot;event&quot;:&quot;addToCart&quot;,&quot;ecommerce&quot;:{&quot;currencyCode&quot;:&quot;EUR&quot;,&quot;add&quot;:{&quot;products&quot;:[{&quot;name&quot;:&quot;Distinctive Image Features from Scale-Invariant Keypoints&quot;,&quot;id&quot;:&quot;1573-1405&quot;,&quot;price&quot;:39.95,&quot;brand&quot;:&quot;Kluwer Academic Publishers&quot;,&quot;category&quot;:&quot;Computer Science&quot;,&quot;variant&quot;:&quot;ppv-article&quot;,&quot;quantity&quot;:1}]}}});" value="Buy article PDF">
    </form>
   </div>
  </div>
  <script>dataLayer.push({"ecommerce":{"currency":"EUR","impressions":[{"name":"Distinctive Image Features from Scale-Invariant Keypoints","id":"1573-1405","price":39.95,"brand":"Kluwer Academic Publishers","category":"Computer Science","variant":"ppv-article","quantity":1}]}});</script>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" rel="nofollow" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                            link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1023/B:VISI.0000029664.99615.94&journal=1573-1405&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
 <script style="display: none">
                ;(function () {
                    var timestamp = Date.now()
                    document.write('<div data-id="id_'+ timestamp +'"></div>')

                    var head = document.getElementsByTagName("head")[0]
                    var script = document.createElement("script")
                    script.type = "text/javascript"
                    script.src = "https://buy.springer.com/assets/js/buybox-bundle-abe5f44a67.js"
                    script.id = "ecommerce-scripts-" + timestamp
                    head.appendChild(script)

                    var buybox = document.querySelector("[data-id=id_"+ timestamp +"]").parentNode

                    ;[].slice.call(buybox.querySelectorAll(".buying-option")).forEach(init)

                    function init(buyingOption, index) {
                        var form = buyingOption.querySelector("form")

                        if (form) {
                            var formAction = form.getAttribute("action")
                            document.querySelector("#ecommerce-scripts-" + timestamp).addEventListener("load", bindModal(form, formAction, timestamp, index), false)
                        }
                    }

                    function bindModal(form, formAction, timestamp, index) {
                        var weHasBrowserSupport = window.fetch && Array.from

                        return function() {
                            console.log("ecommerce-scripts loaded, attempting to init modal ")
                            var Buybox = EcommScripts ? EcommScripts.Buybox : null
                            var Modal = EcommScripts ? EcommScripts.Modal : null
                            
                            if (weHasBrowserSupport && Buybox && Modal) {
                                var modalID = "ecomm-modal_" + timestamp + "_" + index
                                
                                var modal = new Modal(modalID)
                                modal.domEl.addEventListener("close", close)
                                function close() {
                                    form.querySelector("button[type=submit]").focus()
                                }

                                var cartURL = "/cart"
                                var cartModalURL = "/cart?messageOnly=1"

                                form.setAttribute(
                                    "action",
                                    formAction.replace(cartURL, cartModalURL)
                                )
                                
                                var formSubmit = Buybox.interceptFormSubmit(
                                    Buybox.fetchFormAction(window.fetch),
                                    function(responseBody) {
                                        document.body.dispatchEvent(new Event("updatedCart"))
                                        Buybox.triggerModalAfterAddToCartSuccess(modal)(responseBody)
                                    },
                                    function() {
                                        form.removeEventListener("submit", formSubmit, false)
                                        form.setAttribute(
                                            "action",
                                            formAction.replace(cartModalURL, cartURL)
                                        )
                                        form.submit()
                                    }
                                )

                                form.addEventListener("submit", formSubmit, false)
                                
                                document.body.appendChild(modal.domEl)
                            } else {
                                console.log("binding failed:", weHasBrowserSupport, EcommScripts)
                            }
                        }
                    }
                })()
              </script>
</div>
                                </div>
                            
                        
                        <div class="u-display-none">
                            
                        </div>
                    

                    <div data-test="cobranding-download">
                        
                    </div>

                    <div class="app-checklist-banner--on-mobile">
                        
                    </div>

                    

                    <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ul class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR1">Arya, S. and Mount, D.M. 1993. Approximate nearest neighbor queries in fixed dimensions. In <i>Fourth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA'93),</i>pp. 271280.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR2">Arya, S., Mount, D.M., Netanyahu, N.S., Silverman, R., and Wu, A.Y. 1998. Anoptimal algorithm for approximate nearest neighbor searching. <i>Journal of the ACM</i>, 45:891923.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Anoptimal%20algorithm%20for%20approximate%20nearest%20neighbor%20searching&amp;journal=Journal%20of%20the%20ACM&amp;volume=45&amp;pages=891-923&amp;publication_year=1998&amp;author=Arya%2CS.&amp;author=Mount%2CD.M.&amp;author=Netanyahu%2CN.S.&amp;author=Silverman%2CR.&amp;author=Wu%2CA.Y.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR3">Ballard, D.H. 1981. Generalizing the Hough transform to detect arbitrary patterns. <i>Pattern Recognition</i>, 13(2):111122.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Generalizing%20the%20Hough%20transform%20to%20detect%20arbitrary%20patterns&amp;journal=Pattern%20Recognition&amp;volume=13&amp;issue=2&amp;pages=111-122&amp;publication_year=1981&amp;author=Ballard%2CD.H.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR4">Basri, R. and Jacobs, D.W. 1997. Recognition using region correspondences. <i>International Journal of Computer Vision</i>, 25(2):145166.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Recognition%20using%20region%20correspondences&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;volume=25&amp;issue=2&amp;pages=145-166&amp;publication_year=1997&amp;author=Basri%2CR.&amp;author=Jacobs%2CD.W.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR5">Baumberg, A. 2000. Reliable feature matching across widely separated views. In <i>Conference on ComputerVision andPattern Recognition</i>, Hilton Head, South Carolina, pp. 774781.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR6">Beis, J. and Lowe, D.G. 1997. Shape indexing using approximate nearest-neighbour search in high-dimensional spaces. In <i>Conference on Computer Vision and Pattern Recognition</i>, Puerto Rico, pp. 10001006.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR7">Brown, M. and Lowe, D.G. 2002. Invariant features from interest point groups. In <i>British Machine Vision Conference</i>, Cardiff, Wales, pp. 656665.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR8">Carneiro, G. and Jepson, A.D. 2002. Phase-based local features. In <i>European Conference on Computer Vision (ECCV)</i>, Copenhagen, Denmark, pp. 282296.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR9">Crowley, J.L. and Parker, A.C. 1984. Arepresentation for shape based on peaks and ridges in the difference of low-pass transform. <i>IEEE Trans. on Pattern Analysis and Machine Intelligence</i>, 6(2):156170.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Arepresentation%20for%20shape%20based%20on%20peaks%20and%20ridges%20in%20the%20difference%20of%20low-pass%20transform&amp;journal=IEEE%20Trans.%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;volume=6&amp;issue=2&amp;pages=156-170&amp;publication_year=1984&amp;author=Crowley%2CJ.L.&amp;author=Parker%2CA.C.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR10">Edelman, S., Intrator, N., and Poggio, T. 1997. Complex cells and object recognition. Unpublished manuscript: http://kybele.psych.cornell.edu/~edelman/archive.html</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR11">Fergus, R., Perona, P., and Zisserman, A. 2003. Object class recognition by unsupervised scale-invariant learning. In <i>IEEE Conference on Computer Vision and Pattern Recognition</i>, Madison, Wisconsin, pp. 264271.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR12">Friedman, J.H., Bentley, J.L., and Finkel, R.A. 1977. An algorithm for finding best matches in logarithmic expected time. <i>ACMTransactions on Mathematical Software</i>, 3(3):209226.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20algorithm%20for%20finding%20best%20matches%20in%20logarithmic%20expected%20time&amp;journal=ACMTransactions%20on%20Mathematical%20Software&amp;volume=3&amp;issue=3&amp;pages=209-226&amp;publication_year=1977&amp;author=Friedman%2CJ.H.&amp;author=Bentley%2CJ.L.&amp;author=Finkel%2CR.A.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR13">Funt, B.V. and Finlayson, G.D. 1995. Color constant color indexing. <i>IEEE Trans. on Pattern Analysis and Machine Intelligence</i>, 17(5):522529.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Color%20constant%20color%20indexing&amp;journal=IEEE%20Trans.%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;volume=17&amp;issue=5&amp;pages=522-529&amp;publication_year=1995&amp;author=Funt%2CB.V.&amp;author=Finlayson%2CG.D.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR14">Grimson, E. 1990. <i>Object Recognition by Computer: The Role of Geometric Constraints</i>, The MIT Press: Cambridge, MA.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Object%20Recognition%20by%20Computer%3A%20The%20Role%20of%20Geometric%20Constraints&amp;publication_year=1990&amp;author=Grimson%2CE.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR15">Harris, C. 1992. Geometry from visual motion. In <i>Active Vision</i>, A. Blake and A. Yuille (Eds.), MIT Press, pp. 263284.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR16">Harris, C. and Stephens, M. 1988. Acombined corner and edge detector. In <i>Fourth Alvey Vision Conference</i>, Manchester, UK, pp. 147151.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR17">Hartley, R. and Zisserman, A. 2000. <i>Multiple view geometry in computer vision</i>, Cambridge University Press: Cambridge, UK.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Multiple%20view%20geometry%20in%20computer%20vision&amp;publication_year=2000&amp;author=Hartley%2CR.&amp;author=Zisserman%2CA.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR18">Hough, P.V.C. 1962. Method and means for recognizing complex patterns. U.S. Patent 3069654.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR19">Koenderink, J.J. 1984. The structure of images. <i>Biological Cybernetics</i>, 50:363396.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20structure%20of%20images&amp;journal=Biological%20Cybernetics&amp;volume=50&amp;pages=363-396&amp;publication_year=1984&amp;author=Koenderink%2CJ.J.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR20">Lindeberg, T. 1993. Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention. <i>International Journal of Computer Vision</i>, 11(3):283318.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Detecting%20salient%20blob-like%20image%20structures%20and%20their%20scales%20with%20a%20scale-space%20primal%20sketch%3A%20A%20method%20for%20focus-of-attention&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;volume=11&amp;issue=3&amp;pages=283-318&amp;publication_year=1993&amp;author=Lindeberg%2CT.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR21">Lindeberg, T. 1994. Scale-space theory: A basic tool for analysing structures at different scales. <i>Journal of Applied Statistics</i>, 21(2):224270.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Scale-space%20theory%3A%20A%20basic%20tool%20for%20analysing%20structures%20at%20different%20scales&amp;journal=Journal%20of%20Applied%20Statistics&amp;volume=21&amp;issue=2&amp;pages=224-270&amp;publication_year=1994&amp;author=Lindeberg%2CT.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR22">Lowe, D.G. 1991. Fitting parameterized three-dimensional models to images. <i>IEEE Trans. on Pattern Analysis and Machine Intelligence</i>, 13(5):441450.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Fitting%20parameterized%20three-dimensional%20models%20to%20images&amp;journal=IEEE%20Trans.%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;volume=13&amp;issue=5&amp;pages=441-450&amp;publication_year=1991&amp;author=Lowe%2CD.G.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR23">Lowe, D.G. 1999. Object recognition from local scale-invariant features. In <i>International Conference on Computer Vision</i>, Corfu, Greece, pp. 11501157.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR24">Lowe, D.G. 2001. Local feature view clustering for 3D object recognition. <i>IEEE Conference on Computer Vision and Pattern Recognition</i>, Kauai, Hawaii, pp. 682688.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR25">Luong, Q.T. and Faugeras, O.D. 1996. The fundamental matrix: Theory, algorithms, and stability analysis. <i>International Journal of Computer Vision</i>, 17(1):4376.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20fundamental%20matrix%3A%20Theory%2C%20algorithms%2C%20and%20stability%20analysis&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;volume=17&amp;issue=1&amp;pages=43-76&amp;publication_year=1996&amp;author=Luong%2CQ.T.&amp;author=Faugeras%2CO.D.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR26">Matas, J., Chum, O., Urban, M., and Pajdla, T. 2002. Robust wide baseline stereo from maximally stable extremal regions. In <i>British Machine Vision Conference</i>, Cardiff, Wales, pp. 384393.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR27">Mikolajczyk, K. 2002. Detection of local features invariant to affine transformations, Ph.D. thesis, Institut National Polytechnique de Grenoble, France.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR28">Mikolajczyk, K. and Schmid, C. 2002. An affine invariant interest point detector. In <i>European Conference on Computer Vision (ECCV)</i>, Copenhagen, Denmark, pp. 128142.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR29">Mikolajczyk, K., Zisserman, A., and Schmid, C. 2003. Shape recognition with edge-based features. In <i>Proceedings of the British Machine Vision Conference</i>, Norwich, U.K.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR30">Moravec, H. 1981. Rover visual obstacle avoidance. In <i>International Joint Conference on Artificial Intelligence</i>, Vancouver, Canada, pp. 785790.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR31">Nelson, R.C. and Selinger, A. 1998. Large-scale tests of a keyed, appearance-based 3-D object recognition system. <i>Vision Research</i>, 38(15):24692488.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Large-scale%20tests%20of%20a%20keyed%2C%20appearance-based%203-D%20object%20recognition%20system&amp;journal=Vision%20Research&amp;volume=38&amp;issue=15&amp;pages=2469-2488&amp;publication_year=1998&amp;author=Nelson%2CR.C.&amp;author=Selinger%2CA.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR32">Pope, A.R. and Lowe, D.G. 2000. Probabilistic models of appearance for 3-D object recognition. <i>International Journal of Computer Vision</i>, 40(2):149167.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Probabilistic%20models%20of%20appearance%20for%203-D%20object%20recognition&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;volume=40&amp;issue=2&amp;pages=149-167&amp;publication_year=2000&amp;author=Pope%2CA.R.&amp;author=Lowe%2CD.G.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR33">Pritchard, D. and Heidrich,W. 2003. Cloth motion capture. <i>Computer Graphics Forum (Eurographics 2003)</i>, 22(3):263271.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloth%20motion%20capture&amp;journal=Computer%20Graphics%20Forum%20%28Eurographics%202003%29&amp;volume=22&amp;issue=3&amp;pages=263-271&amp;publication_year=2003&amp;author=Pritchard%2CD.&amp;author=Heidrich%2CW.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR34">Schaffalitzky, F. and Zisserman, A. 2002. Multi-view matching for unordered image sets, or 'How do I organize my holiday snaps?' In <i>European Conference on Computer Vision</i>, Copenhagen, Denmark, pp. 414431.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR35">Schiele, B. and Crowley, J.L. 2000. Recognition without correspondence using multidimensional receptive field histograms. <i>International Journal of Computer Vision</i>, 36(1):3150.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Recognition%20without%20correspondence%20using%20multidimensional%20receptive%20field%20histograms&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;volume=36&amp;issue=1&amp;pages=31-50&amp;publication_year=2000&amp;author=Schiele%2CB.&amp;author=Crowley%2CJ.L.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR36">Schmid, C. and Mohr, R. 1997. Local grayvalue invariants for image retrieval. <i>IEEE Trans. on Pattern Analysis and Machine Intelligence</i>, 19(5):530534.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Local%20grayvalue%20invariants%20for%20image%20retrieval&amp;journal=IEEE%20Trans.%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;volume=19&amp;issue=5&amp;pages=530-534&amp;publication_year=1997&amp;author=Schmid%2CC.&amp;author=Mohr%2CR.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR37">Se, S., Lowe, D.G., and Little, J. 2001. Vision-based mobile robot localization and mapping using scale-invariant features. In <i>International Conference on Robotics and Automation</i>, Seoul, Korea, pp. 20512058.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR38">Se, S., Lowe, D.G., and Little, J. 2002. Global localization using distinctive visual features. In <i>International Conference on Intelligent Robots and Systems, IROS 2002</i>, Lausanne, Switzerland, pp. 226231.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR39">Shokoufandeh, A., Marsic, I., and Dickinson, S.J. 1999. View-based object recognition using saliency maps. <i>Image and Vision Computing</i>, 17:445460.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=View-based%20object%20recognition%20using%20saliency%20maps&amp;journal=Image%20and%20Vision%20Computing&amp;volume=17&amp;pages=445-460&amp;publication_year=1999&amp;author=Shokoufandeh%2CA.&amp;author=Marsic%2CI.&amp;author=Dickinson%2CS.J.">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR40">Torr, P. 1995. Motion segmentation and outlier detection, Ph.D. Thesis, Dept. of Engineering Science, University of Oxford, UK.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR41">Tuytelaars, T. and Van Gool, L. 2000. Wide baseline stereo based on local, affinely invariant regions. In <i>British Machine Vision Conference</i>, Bristol, UK, pp. 412422.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR42">Weber, M., Welling, M., and Perona, P. 2000. Unsupervised learning of models for recognition. In <i>European Conference on Computer Vision</i>, Dublin, Ireland, pp. 1832.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR43">Witkin, A.P. 1983. Scale-space filtering. In <i>International Joint Conference on Artificial Intelligence</i>, Karlsruhe, Germany, pp. 10191022.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR44">Zhang, Z., Deriche, R., Faugeras, O., and Luong, Q.T. 1995. Arobust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry. <i>Artificial Intelligence</i>, 78:87119.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Arobust%20technique%20for%20matching%20two%20uncalibrated%20images%20through%20the%20recovery%20of%20the%20unknown%20epipolar%20geometry&amp;journal=Artificial%20Intelligence&amp;volume=78&amp;pages=87-119&amp;publication_year=1995&amp;author=Zhang%2CZ.&amp;author=Deriche%2CR.&amp;author=Faugeras%2CO.&amp;author=Luong%2CQ.T.">
                    Google Scholar</a>
                </p></li></ul><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1023/B:VISI.0000029664.99615.94?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Computer Science Department, University of British Columbia, Vancouver, B.C., Canada</p><p class="c-article-author-affiliation__authors-list">David G. Lowe</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-David_G_-Lowe"><span class="c-article-authors-search__title u-h3 js-search-name">David G. Lowe</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=David%20G.%20Lowe" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=David%20G.%20Lowe" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22David%20G.%20Lowe%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Distinctive%20Image%20Features%20from%20Scale-Invariant%20Keypoints&amp;author=David%20G.%20Lowe&amp;contentID=10.1023%2FB%3AVISI.0000029664.99615.94&amp;copyright=Kluwer%20Academic%20Publishers&amp;publication=0920-5691&amp;publicationDate=2004-11&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Lowe, D.G. Distinctive Image Features from Scale-Invariant Keypoints.
                    <i>International Journal of Computer Vision</i> <b>60</b>, 91110 (2004). https://doi.org/10.1023/B:VISI.0000029664.99615.94</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1023/B:VISI.0000029664.99615.94?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2004-11">November 2004</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1023/B:VISI.0000029664.99615.94</span></p></li></ul><div data-component="share-box" class="u-mt-0"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading u-mt-0">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span>invariant features</span></li><li class="c-article-subject-list__subject"><span>object recognition</span></li><li class="c-article-subject-list__subject"><span>scale invariance</span></li><li class="c-article-subject-list__subject"><span>image matching</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                
                    
                        
                            <div class="u-mb-16 u-clear-both">
                                <a href="//wayf.springernature.com?redirect_uri&#x3D;https%3A%2F%2Flink.springer.com%2Farticle%2F10.1023%2FB%3AVISI.0000029664.99615.94" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-track="click" data-track-action="institution access" data-track-label="button">
                                    <span data-test="access-via-institution">Access via your institution</span>
                                    <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-springer-arrow-right"></use></svg>
                                </a>
                            </div>
                        
                    
                

                <div data-test="download-article-link-wrapper" class="js-context-bar-sticky-point-desktop">
                    
                </div>

                

                <div data-test="collections">
                    
    

                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        
                            
                                <div data-test="buy-box-desktop" class="c-article-buy-box">
                                    <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <!-- rendered: 2023-04-27T02:54:23.285344 -->
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box buying-option" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">39,95 </p>
    <p class="buybox__price-info">Price includes VAT (New Zealand)<br></p>
    <form action="https://order.springer.com/public/cart" method="post">
     <input type="hidden" name="type" value="article"><input type="hidden" name="doi" value="10.1023/B:VISI.0000029664.99615.94"><input type="hidden" name="isxn" value="1573-1405"><input type="hidden" name="contenttitle" value="Distinctive Image Features from Scale-Invariant Keypoints"><input type="hidden" name="copyrightyear" value="2004"><input type="hidden" name="year" value=""><input type="hidden" name="authors" value="David G. Lowe"><input type="hidden" name="title" value="International Journal of Computer Vision"><input type="hidden" name="mac" value="37FA1C595DD2E584CE3B33C93541054C"><input type="submit" class="c-box__button" onclick="dataLayer.push({&quot;event&quot;:&quot;addToCart&quot;,&quot;ecommerce&quot;:{&quot;currencyCode&quot;:&quot;EUR&quot;,&quot;add&quot;:{&quot;products&quot;:[{&quot;name&quot;:&quot;Distinctive Image Features from Scale-Invariant Keypoints&quot;,&quot;id&quot;:&quot;1573-1405&quot;,&quot;price&quot;:39.95,&quot;brand&quot;:&quot;Kluwer Academic Publishers&quot;,&quot;category&quot;:&quot;Computer Science&quot;,&quot;variant&quot;:&quot;ppv-article&quot;,&quot;quantity&quot;:1}]}}});" value="Buy article PDF">
    </form>
   </div>
  </div>
  <script>dataLayer.push({"ecommerce":{"currency":"EUR","impressions":[{"name":"Distinctive Image Features from Scale-Invariant Keypoints","id":"1573-1405","price":39.95,"brand":"Kluwer Academic Publishers","category":"Computer Science","variant":"ppv-article","quantity":1}]}});</script>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" rel="nofollow" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                            link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1023/B:VISI.0000029664.99615.94&journal=1573-1405&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
 <script style="display: none">
                ;(function () {
                    var timestamp = Date.now()
                    document.write('<div data-id="id_'+ timestamp +'"></div>')

                    var head = document.getElementsByTagName("head")[0]
                    var script = document.createElement("script")
                    script.type = "text/javascript"
                    script.src = "https://buy.springer.com/assets/js/buybox-bundle-abe5f44a67.js"
                    script.id = "ecommerce-scripts-" + timestamp
                    head.appendChild(script)

                    var buybox = document.querySelector("[data-id=id_"+ timestamp +"]").parentNode

                    ;[].slice.call(buybox.querySelectorAll(".buying-option")).forEach(init)

                    function init(buyingOption, index) {
                        var form = buyingOption.querySelector("form")

                        if (form) {
                            var formAction = form.getAttribute("action")
                            document.querySelector("#ecommerce-scripts-" + timestamp).addEventListener("load", bindModal(form, formAction, timestamp, index), false)
                        }
                    }

                    function bindModal(form, formAction, timestamp, index) {
                        var weHasBrowserSupport = window.fetch && Array.from

                        return function() {
                            console.log("ecommerce-scripts loaded, attempting to init modal ")
                            var Buybox = EcommScripts ? EcommScripts.Buybox : null
                            var Modal = EcommScripts ? EcommScripts.Modal : null
                            
                            if (weHasBrowserSupport && Buybox && Modal) {
                                var modalID = "ecomm-modal_" + timestamp + "_" + index
                                
                                var modal = new Modal(modalID)
                                modal.domEl.addEventListener("close", close)
                                function close() {
                                    form.querySelector("button[type=submit]").focus()
                                }

                                var cartURL = "/cart"
                                var cartModalURL = "/cart?messageOnly=1"

                                form.setAttribute(
                                    "action",
                                    formAction.replace(cartURL, cartModalURL)
                                )
                                
                                var formSubmit = Buybox.interceptFormSubmit(
                                    Buybox.fetchFormAction(window.fetch),
                                    function(responseBody) {
                                        document.body.dispatchEvent(new Event("updatedCart"))
                                        Buybox.triggerModalAfterAddToCartSuccess(modal)(responseBody)
                                    },
                                    function() {
                                        form.removeEventListener("submit", formSubmit, false)
                                        form.setAttribute(
                                            "action",
                                            formAction.replace(cartModalURL, cartURL)
                                        )
                                        form.submit()
                                    }
                                )

                                form.addEventListener("submit", formSubmit, false)
                                
                                document.body.appendChild(modal.domEl)
                            } else {
                                console.log("binding failed:", weHasBrowserSupport, EcommScripts)
                            }
                        }
                    }
                })()
              </script>
</div>
                                </div>
                            
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu><div class="c-ad c-ad--300x250">
    <div class="c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-MPU1"
             class="div-gpt-ad grade-c-hide"
             data-pa11y-ignore
             data-gpt
             data-gpt-unitpath="/270604982/springerlink/11263/article"
             data-gpt-sizes="300x250" data-test="MPU1-ad"
             data-gpt-targeting="pos=MPU1;articleid=Art1;">
        </div>
    </div>
</div>

</div>
                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>

    
    <script>
            
    </script>
    
        
    <footer class="app-footer" role="contentinfo" data-test="springerlink-footer">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" data-cc-action="preferences" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a href="https://support.springer.com/en/support/home">FAQ</a></li>
                <li><a id="contactus-footer-link" href="https://support.springer.com/en/support/solutions/articles/6000206179-contacting-us">Contact us</a></li>
                <li><a href="https://www.springer.com/gp/shop/promo/affiliate/springer-nature">Affiliate program</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 202.36.179.106</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-b88bf25ad4.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2023 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
    </footer>



    </div>
    
    

    
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 10 10" xmlns="http://www.w3.org/2000/svg">
            <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="currentColor" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-success" viewBox="0 0 18 18">
            <path d="M9 0a9 9 0 110 18A9 9 0 019 0zm3.486 4.982l-4.718 5.506L5.14 8.465a.991.991 0 00-1.423.133 1.06 1.06 0 00.13 1.463l3.407 2.733a1 1 0 001.387-.133l5.385-6.334a1.06 1.06 0 00-.116-1.464.991.991 0 00-1.424.119z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
        <symbol id="icon-warning" viewBox="0 0 18 18">
            <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-plus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-minus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-error" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-springer-arrow-left">
            <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/>
        </symbol>
        <symbol id="icon-springer-arrow-right">
            <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/>
        </symbol>
        <symbol id="icon-arrow-up" viewBox="0 0 16 16">
            <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-tick" viewBox="0 0 24 24">
            <path d="M12,24 C5.372583,24 0,18.627417 0,12 C0,5.372583 5.372583,0 12,0 C18.627417,0 24,5.372583 24,12 C24,18.627417 18.627417,24 12,24 Z M7.657,10.79 C7.45285634,10.6137568 7.18569967,10.5283283 6.91717333,10.5534259 C6.648647,10.5785236 6.40194824,10.7119794 6.234,10.923 C5.87705269,11.3666969 5.93445559,12.0131419 6.364,12.387 L10.261,15.754 C10.6765468,16.112859 11.3037113,16.0695601 11.666,15.657 L17.759,8.713 C18.120307,8.27302248 18.0695334,7.62621189 17.644,7.248 C17.4414817,7.06995024 17.1751516,6.9821166 16.9064461,7.00476032 C16.6377406,7.02740404 16.3898655,7.15856958 16.22,7.368 L10.768,13.489 L7.657,10.79 Z"/>
        </symbol>
        <symbol id="icon-expand-image" viewBox="0 0 18 18">
            <path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-close" viewBox="0 0 16 16">
            <path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-right" viewBox="0 0 7 12">
            <path d="M2.782 5 .3 2.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 0 1 1.417 0l4.176 4.177a1.001 1.001 0 0 1 0 1.416l-4.176 4.177a.991.991 0 0 1-1.4.016A1 1 0 0 1 .3 9.481L2.782 7l1.013-.998L2.782 5Z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-checklist-banner" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 56.69 56.69" style="enable-background:new 0 0 56.69 56.69" xml:space="preserve">
            <path style="fill:none" d="M0 0h56.69v56.69H0z"/><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/>
        </symbol>
        <symbol id="icon-get-ftr" viewBox="0 0 24 24">
            <path fill="#0D8D8A" fill-rule="nonzero" d="M24 12c0 6.627-5.373 12-12 12-2.102 0-4.078-.54-5.796-1.49l1.485-1.484A9.96 9.96 0 0 0 12 22c5.523 0 10-4.477 10-10a9.96 9.96 0 0 0-.974-4.31l1.484-1.486A11.946 11.946 0 0 1 24 12ZM12 0c2.102 0 4.079.54 5.797 1.49l-1.485 1.485A9.96 9.96 0 0 0 12 2C6.477 2 2 6.477 2 12c0 1.544.35 3.006.975 4.312L1.49 17.797A11.946 11.946 0 0 1 0 12C0 5.373 5.373 0 12 0Z"/>
            <circle cx="12" cy="12" r="5.333" fill="#096A73"/>
        </symbol>
        <symbol id="icon-github" viewBox="0 0 100 100">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill="#24292f"/>
        </symbol>
        <symbol id="icon-search-filter" viewBox="0 0 29 29">
            <defs><style>.cls-1{fill:none;}</style></defs><title/><g data-name="Layer 2" id="Layer_2"><path d="M28,9H11a1,1,0,0,1,0-2H28a1,1,0,0,1,0,2Z"/><path d="M7,9H4A1,1,0,0,1,4,7H7A1,1,0,0,1,7,9Z"/><path d="M21,17H4a1,1,0,0,1,0-2H21a1,1,0,0,1,0,2Z"/><path d="M11,25H4a1,1,0,0,1,0-2h7a1,1,0,0,1,0,2Z"/><path d="M9,11a3,3,0,1,1,3-3A3,3,0,0,1,9,11ZM9,7a1,1,0,1,0,1,1A1,1,0,0,0,9,7Z"/><path d="M23,19a3,3,0,1,1,3-3A3,3,0,0,1,23,19Zm0-4a1,1,0,1,0,1,1A1,1,0,0,0,23,15Z"/><path d="M13,27a3,3,0,1,1,3-3A3,3,0,0,1,13,27Zm0-4a1,1,0,1,0,1,1A1,1,0,0,0,13,23Z"/><path d="M28,17H25a1,1,0,0,1,0-2h3a1,1,0,0,1,0,2Z"/><path d="M28,25H15a1,1,0,0,1,0-2H28a1,1,0,0,1,0,2Z"/></g><g id="frame"><rect class="cls-1" height="32" width="32"/></g>
        </symbol>
        <symbol id="icon-book" viewBox="0 0 18 18">
            <path
                d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z"
                fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-submit-open" viewBox="0 0 16 17">
            <path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/>
        </symbol>
    </svg>

</body>
</html>


